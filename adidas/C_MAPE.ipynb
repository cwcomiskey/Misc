{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "source": [
    "# 0.0 Modules, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import clone\n",
    "from sklearn.externals.six.moves import xrange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import bokeh.io\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "# init_notebook_mode()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import itertools\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "import time\n",
    "import dateutil.parser\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import gc\n",
    "import zipfile\n",
    "import sys, getopt\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from io import StringIO\n",
    "\n",
    "import dask.dataframe as dd\n",
    "#from chest import Chest\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "# Magic function to make matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "import dask.dataframe as ddf\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "# plotly.tools.set_credentials_file(username='duplinskiy', api_key='RsZHhxIiAGGu7FN9P4bu')\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Useful example article -- C77124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat[dat['article_number'] == 'C77124']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "\n",
    "    - Small: < 100 units\n",
    "    - Large: > 30000 units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### MAPE: FW17, SS18, FW18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (pd.DataFrame(\n",
    "    pd.read_csv('Buyers predictions.csv', low_memory=False, index_col = 0))\n",
    "         [['season', 'ecom_marketing_forecast']].\n",
    "         reset_index().\n",
    "        dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dat = pd.read_csv('dat.csv', low_memory=False, index_col = 0) # Wall time: 1min 47s\n",
    "# dat['consumer_order_date'] = pd.to_datetime(dat['consumer_order_date'])\n",
    "# dat = dat[dat['gross_demand_quantity'] != 0] \n",
    "# dat.drop(['sales_organization', 'country', 'brand', 'sold_qty', 'std_margin', \n",
    "#           'return_qty', 'article_promotion_main_category_group', 'fw_or_ss'], \n",
    "#          inplace=True, axis = 1)\n",
    "# dat = dat.groupby(by = ['article_number', 'season']).agg('sum')[['net_qty']] # aggregate by year\n",
    "# dat.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dat.to_csv('dat_raw_MAPE.csv')\n",
    "dat = pd.read_csv('dat_raw_MAPE.csv', low_memory=False, index_col = 0,) # to calculate raw MAPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge predictions\n",
    "dat1 = pd.merge(dat, preds, left_on=['article_number', 'season'], right_on=['article', 'season'])\n",
    "dat1 = dat1[dat1['season'] != 'SS19'].drop('article', axis = 1)\n",
    "dat1 = dat1[(dat1['net_qty'] != 0) & (dat1['ecom_marketing_forecast'] != 0)]\n",
    "del dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos DataFrame\n",
    "\n",
    "# dat.head() # 47756 \n",
    "# preds.head()\n",
    "\n",
    "dat1.shape\n",
    "dat1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pct error = [forecast - actual]/actual = (net_qty + stock - net_qty)/net_qty\n",
    "dat1['APE'] = abs(dat1['ecom_marketing_forecast'] - dat1['net_qty'])/dat1['net_qty']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = [0, 100, 10000, 30000]\n",
    "dat1['bin'] = pd.cut(np.array(dat1['net_qty']), bins)\n",
    "\n",
    "d = dat1.groupby(['season', 'bin'])['APE'].describe()[['count', 'mean', '50%']]\n",
    "\n",
    "order = {'SS17': 0, 'FW17': 1, 'SS18': 2, 'FW18': 3, 'SS19': 4}\n",
    "d['order_id'] = [order[i] for i in d.reset_index()['season']]\n",
    "\n",
    "d.sort_values(by = ['order_id', 'bin'], inplace=True)\n",
    "d.drop('order_id', axis = 1, inplace=True)\n",
    "\n",
    "d.round().astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Corrected-MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": false
   },
   "source": [
    "### Understock EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carryover = pd.read_csv('Stock left and of season.csv', low_memory=False, index_col = 0, usecols=['season', 'article_number', 'ecom_available_stock', 'buy_availability']) \n",
    "carryover = (pd.DataFrame(carryover.groupby(['article_number', 'season'])['ecom_available_stock'].min()).reset_index())\n",
    "\n",
    "dat0 = pd.read_csv('dat_raw_MAPE.csv', low_memory=False, index_col = 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = dat0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = pd.merge(dat, carryover, left_on=['article_number', 'season'], right_on=['article_number', 'season']) # Add end of season stock information\n",
    "dat_understock = dat[dat['ecom_available_stock'] == 0] # leftover was 0, so understocked \n",
    "dat_understock = dat_understock[dat_understock['season'] != 'SS19'] # remove current season\n",
    "dat_understock = dat_understock[dat_understock['net_qty'] > 100] # remove small potatoes items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Sort & order by season ---\n",
    "bins = [0, 100, 1000, 30000]\n",
    "dat_understock['bin'] = pd.cut(np.array(dat_understock['net_qty']), bins)\n",
    "\n",
    "d = pd.DataFrame(dat_understock.groupby(['season', 'bin'])['article_number'].describe()['count'])\n",
    "\n",
    "order = {'SS17': 0, 'FW17': 1, 'SS18': 2, 'FW18': 3, 'SS19': 4}\n",
    "d['order_id'] = [order[i] for i in d.reset_index()['season']]\n",
    "\n",
    "d.sort_values(by = ['order_id', 'bin'], inplace=True)\n",
    "d.drop('order_id', axis = 1, inplace=True)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-MAPE: Overstock EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearance = pd.read_csv('Sale Data/Sale data FW17.csv', low_memory=False, index_col = 0) \n",
    "\n",
    "# clearance = clearance.reset_index() # groupby('article_number').resample('W')\n",
    "# clearance['consumer_order_date'] = pd.to_datetime(clearance['consumer_order_date'])\n",
    "# clearance.set_index('consumer_order_date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat0 = pd.read_csv('dat.csv', low_memory=False, index_col = 0) # Wall time: 1min 47s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Johannes said 'SALE' is Clearance, and outlet won't contribute much\n",
    "SALE = dat0[dat0['article_promotion_main_category_group'] == 'SALE']\n",
    "\n",
    "SALE['consumer_order_date'] = pd.to_datetime(SALE['consumer_order_date'])\n",
    "SALE.set_index('consumer_order_date', inplace = True)\n",
    "\n",
    "SALE2 = SALE[['article_number', 'season', 'net_qty']].groupby(['article_number', 'season']).resample('W').sum() # 'aggregate' to weekly sums by article\n",
    "SALE2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAM\n",
    "plt.rcParams[\"figure.figsize\"] = [18,4]\n",
    "SALE2['consumer_order_date'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALE2.groupby(['consumer_order_date'])['net_qty'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Outlet ---\n",
    "outlet = dat0[dat0['article_promotion_main_category_group'] == 'Outlet']\n",
    "\n",
    "outlet['consumer_order_date'] = pd.to_datetime(outlet['consumer_order_date'])\n",
    "outlet.set_index('consumer_order_date', inplace = True)\n",
    "\n",
    "outlet2 = outlet[['article_number', 'season', 'net_qty']].groupby(['article_number', 'season']).resample('W').sum()\n",
    "outlet2.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [18,4]\n",
    "outlet2['consumer_order_date'].hist(bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-MAPE over/stock plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "- Spring Summer: (SS) 1 December -- 31 May\n",
    "- Fall Winter: (FW) 1 June -- 30 November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat0 = pd.read_csv('dat.csv', low_memory=False, index_col = 0) # Wall time: 1min 47s\n",
    "\n",
    "# dat = dat0.copy()\n",
    "# dat = dat[['consumer_order_date', 'article_number', \n",
    "#             'net_qty', 'article_promotion_main_category_group',\n",
    "#            'season']]\n",
    "# dat['consumer_order_date'] = pd.to_datetime(dat['consumer_order_date'])\n",
    "\n",
    "# dat['clearance'] = (dat['article_promotion_main_category_group'] == 'SALE')\n",
    "# dat.drop('article_promotion_main_category_group', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat.to_csv('dat_clearance.csv')\n",
    "dat = pd.read_csv('dat_clearance.csv', low_memory=False, index_col = 0) \n",
    "dat['consumer_order_date'] = pd.to_datetime(dat['consumer_order_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_wo_clearance = dat.copy()\n",
    "dat_wo_clearance = dat_wo_clearance[dat_wo_clearance['clearance'] != True] # **************\n",
    "dat_wo_clearance = pd.DataFrame(dat_wo_clearance.groupby(['article_number', 'consumer_order_date'])['net_qty'].sum())\n",
    "dat_wo_clearance = dat_wo_clearance.reset_index('article_number').groupby('article_number').resample('W').sum()\n",
    "dat_wo_clearance = pd.DataFrame(dat_wo_clearance.reset_index().groupby('consumer_order_date')['net_qty'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.head()\n",
    "dat_wo_clearance_clearance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Clearance and non-clearance -------\n",
    "dat_both = (pd.merge(dat, dat_wo_clearance, left_on='consumer_order_date', right_index=True).\n",
    "            rename(columns = {'net_qty_y':'Without Clearance', 'net_qty_x':'With Clearance'})\n",
    "           )\n",
    "\n",
    "# With/without Clearance weekly average net_qty \n",
    "plt.rcParams[\"figure.figsize\"] = [18,4]\n",
    "dat_both.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-MAPE: both corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buy_availability correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dat = pd.read_csv('weekly_dat.csv', low_memory=False, index_col = 0) # Wall time: 10.9 s\n",
    "dat['consumer_order_date'] = pd.to_datetime(dat['consumer_order_date'])\n",
    "\n",
    "dat['week'] = [t.week for t in dat['consumer_order_date']]\n",
    "dat['year'] = [t.year for t in dat['consumer_order_date']]\n",
    "\n",
    "buy_avail = pd.read_csv('buy_availability.csv', low_memory=False, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.merge(dat, buy_avail, \n",
    "                left_on = ['article_number', 'year', 'week'], \n",
    "                right_on = ['article_number', 'year', 'week'])\n",
    "\n",
    "# net_qty per season\n",
    "dat_season = pd.DataFrame(\n",
    "    dat.\n",
    "    groupby(['article_number', 'season'])['net_qty'].\n",
    "    sum()\n",
    ")\n",
    "dat_season.rename(columns = {'net_qty':'net_qty_season'}, inplace = True)\n",
    "\n",
    "# WEEKLY averages for articles when fully stocked\n",
    "dat_stocked = pd.DataFrame(\n",
    "    dat[dat['avg(buy_availability)'] > 0.35].\n",
    "    groupby(['article_number', 'season'])['net_qty'].\n",
    "    mean()\n",
    ")\n",
    "dat_stocked.rename(columns = {'net_qty':'net_qty_stocked_weekly_avg'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_stocked['stocked_season_projection'] = 26*dat_stocked['net_qty_stocked_weekly_avg']\n",
    "\n",
    "dat_season = (\n",
    "    pd.merge(dat_season, dat_stocked, left_index=True, right_index=True, how = 'outer').\n",
    "    round()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (pd.DataFrame(\n",
    "    pd.read_csv('Buyers predictions.csv', low_memory=False, index_col = 0))\n",
    "         [['season', 'ecom_marketing_forecast']].\n",
    "         reset_index().\n",
    "        dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_season = pd.merge(\n",
    "    dat_season, \n",
    "    preds, \n",
    "    left_index=True, \n",
    "    right_on=['article', 'season'], \n",
    "    how = 'outer').round().set_index(['article', 'season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_season.drop('net_qty_stocked_weekly_avg', inplace=True, axis = 1)\n",
    "\n",
    "dat_season.rename(\n",
    "    columns = {'stocked_season_projection':'understock_correction', 'net_qty_season': 'net_qty'}, \n",
    "    inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del buy_avail, dat, dat_stocked, stocked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clearance correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wall time: 42.4 s\n",
    "\n",
    "# dat.to_csv('dat_clearance.csv')\n",
    "dat_wo_clearance = pd.read_csv('dat_clearance.csv', low_memory=False, index_col = 0) \n",
    "dat_wo_clearance['consumer_order_date'] = pd.to_datetime(dat_wo_clearance['consumer_order_date'])\n",
    "\n",
    "dat_wo_clearance = dat_wo_clearance[dat_wo_clearance['clearance'] != True]\n",
    "dat_wo_clearance = pd.DataFrame(dat_wo_clearance.groupby(['article_number', 'season'])['net_qty'].sum())\n",
    "\n",
    "dat_wo_clearance.reset_index(inplace=True)\n",
    "dat_wo_clearance.rename(columns = {'article_number': 'article', 'net_qty': 'overstock_correction'}, inplace = True)\n",
    "dat_wo_clearance.set_index(['article', 'season'], inplace = True)\n",
    "\n",
    "del dat_wo_clearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_season = pd.merge(dat_season, dat_wo_clearance, \n",
    "                             how = 'outer', \n",
    "                             left_index = True, \n",
    "                             right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_season.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_season = dat_season[\n",
    "    (dat_season['ecom_marketing_forecast'] != 0)\n",
    "    &\n",
    "    (dat_season['net_qty'] != 0)\n",
    "    &\n",
    "    (dat_season['season'] != 'SS19')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(net, forecast, under, over):\n",
    "    if net > forecast:\n",
    "        return under\n",
    "    elif net < forecast:\n",
    "        return over\n",
    "    else:\n",
    "        return under\n",
    "    \n",
    "\n",
    "\n",
    "dat_season['net_qty*'] = dat_season.apply(lambda row: projection(row[2], row[4], row[3], row[5]), axis = 1)\n",
    "dat_season = dat_season[dat_season['net_qty*'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dat_season.loc[:,'APE'] = pd.to_numeric(\n",
    "    abs(dat_season['net_qty*'] - dat_season['ecom_marketing_forecast'])/dat_season['net_qty*']*100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "bins = [0, 100, 10000, 30000]\n",
    "dat_season.loc[:,'bin'] = pd.cut(np.array(dat_season['net_qty']), bins)\n",
    "\n",
    "d = dat_season.dropna().groupby(['season', 'bin'])['APE'].describe()[['mean', '50%']]\n",
    "\n",
    "order = {'SS17': 0, 'FW17': 1, 'SS18': 2, 'FW18': 3, 'SS19': 4}\n",
    "d['order_id'] = [order[i] for i in d.reset_index()['season']]\n",
    "\n",
    "d.sort_values(by = ['order_id', 'bin'], inplace=True)\n",
    "d.drop('order_id', axis = 1, inplace=True)\n",
    "\n",
    "d.round().astype(int)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

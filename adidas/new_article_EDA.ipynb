{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Modules, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T11:35:36.493237Z",
     "start_time": "2019-10-18T11:35:34.733395Z"
    },
    "hideCode": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import bokeh.io\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "# init_notebook_mode()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import itertools\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "import time\n",
    "import dateutil.parser\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import gc\n",
    "import zipfile\n",
    "import sys, getopt\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from io import StringIO\n",
    "\n",
    "import dask.dataframe as dd\n",
    "#from chest import Chest\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "# Magic function to make matplotlib inline\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "import dask.dataframe as ddf\n",
    "import dask.array as da\n",
    "\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_rows', 800)\n",
    "\n",
    "import scipy\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.tsatools import detrend\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T11:36:11.079931Z",
     "start_time": "2019-10-18T11:35:37.754964Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat0 = pd.read_csv('data/ch4k_df.csv')\n",
    "ref_dat0 = pd.read_csv('data/Article reference data.csv', low_memory = False, error_bad_lines = False, \n",
    "                       usecols = ['article_no', 'model_no', 'art_desc', 'sports_cat_desc', 'rmh_cat_desc', \n",
    "                                  'franchise', 'gender_desc', 'age_group_desc', 'prod_grp_desc', 'prod_type_desc',\n",
    "                                  'brand_desc', 'bus_unit_desc', 'rmh_cat_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T11:36:11.211578Z",
     "start_time": "2019-10-18T11:36:11.082414Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove clearance transactions!!\n",
    "\n",
    "dat0['clearance'] = dat0.clearance.fillna(0) \n",
    "\n",
    "dat0['net_qty'] = (1 - dat0.clearance)*dat0.net_qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T11:56:42.164251Z",
     "start_time": "2019-10-18T11:56:42.144307Z"
    }
   },
   "outputs": [],
   "source": [
    "dat0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Aggregate to Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T11:57:44.132923Z",
     "start_time": "2019-10-18T11:57:40.184477Z"
    }
   },
   "outputs": [],
   "source": [
    "dat = dat0.copy()\n",
    "\n",
    "dat = dat[(dat.net_qty != 0) & (dat.season.isin(['FW15', 'FW16', 'FW17', 'FW18', 'FW19']))].round()\n",
    "\n",
    "dat = dat[['article_number', 'season', 'season_net_qty', 'art_desc', 'sports_cat_desc',\n",
    "       'rmh_cat_desc', 'franchise', 'gender_desc', 'age_group_desc',\n",
    "       'prod_grp_desc', 'prod_type_desc', 'price', 'margin', 'cost']].drop_duplicates()\n",
    "\n",
    "dat = (\n",
    "    dat.\n",
    "    sort_values(['article_number', 'season']).\n",
    "    drop_duplicates(subset = 'article_number').\n",
    "    set_index('article_number').\n",
    "    dropna()\n",
    "      )\n",
    "\n",
    "dat[['price', 'margin', 'cost']] = dat[['price', 'margin', 'cost']].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T11:57:45.567498Z",
     "start_time": "2019-10-18T11:57:45.477432Z"
    }
   },
   "outputs": [],
   "source": [
    "len(dat.index.unique())\n",
    "dat.shape\n",
    "pd.crosstab(index = dat.season, columns = 'count').head() # new articles by season\n",
    "# dat[dat.article_number == '015110']\n",
    "dat.head()\n",
    "dat.loc['015110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm\n",
    "# 1. select artice\n",
    "# 2. select category\n",
    "# 3. filter by same level of category\n",
    "# 4. filter by similar price\n",
    "# 5. retrieve net quantites\n",
    "# 6. repeat 2 - 5 for all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T08:55:38.863886Z",
     "start_time": "2019-10-18T08:55:38.861380Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. 015110\t\n",
    "# 2. 'sports_cat_desc'\n",
    "# 3. 'sports_cat_desc' == 'FOOTBALL/SOCCER'\n",
    "# 4. 70 < price < 110\n",
    "# 5. net_qtys = net_qtys.append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T11:30:26.641996Z",
     "start_time": "2019-10-18T11:30:26.635670Z"
    }
   },
   "outputs": [],
   "source": [
    "int(9 - .2*9)\n",
    "int(p) in range(int(p - 0.2*p), int(p + 0.2*p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T12:18:56.381070Z",
     "start_time": "2019-10-18T12:18:56.376102Z"
    }
   },
   "outputs": [],
   "source": [
    "dat.loc['015110']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T11:49:47.127119Z",
     "start_time": "2019-10-18T11:49:42.572197Z"
    }
   },
   "outputs": [],
   "source": [
    "net_qtys = pd.Series()\n",
    "\n",
    "for a in ['015110']:\n",
    "    for c in ['sports_cat_desc', 'rmh_cat_desc', 'franchise', 'gender_desc', 'age_group_desc', 'prod_grp_desc', 'prod_type_desc']: \n",
    "        a_c_l = dat.loc[a, c] # article_category_level\n",
    "        print(c, ' = ', a_c_l)\n",
    "        \n",
    "        p = dat.loc[a, 'price']\n",
    "        print('price = ', p)\n",
    "        \n",
    "        dat_a = dat[(dat[c] == a_c_l) & ([price in range(int(p - 0.2*p), int(p + 0.2*p)) for price in dat.price])]\n",
    "        print(dat_a.shape)\n",
    "        print()\n",
    "        \n",
    "        net_qtys = net_qtys.append(dat_a.season_net_qty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T12:18:14.575738Z",
     "start_time": "2019-10-18T12:18:14.564227Z"
    }
   },
   "outputs": [],
   "source": [
    "net_qtys.shape\n",
    "len(net_qtys)\n",
    "net_qtys.describe()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T11:59:55.735165Z",
     "start_time": "2019-10-18T11:59:55.531071Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(net_qtys, bins = [0, 100, 250, 500, 750, 1000, 1250, 1500, 1750, 2000, 20000], density = True)\n",
    "# (array([4.52881587e-03, 1.62850089e-03, 5.75466076e-04, 2.46360773e-04,\n",
    "#         1.34161914e-04, 6.72512131e-05, 4.98850770e-05, 3.67753469e-05,\n",
    "#         1.90686984e-05, 1.14450025e-06]),\n",
    "#  array([    0,   100,   250,   500,   750,  1000,  1250,  1500,  1750,\n",
    "#          2000, 20000]),\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T11:48:52.007523Z",
     "start_time": "2019-10-18T11:48:52.001954Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "ecdf = ECDF(net_qtys)\n",
    "\n",
    "ecdf([100, 500, 1000, 2000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EDA Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T11:06:12.348050Z",
     "start_time": "2019-10-08T11:06:12.077536Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ---- Plot -----\n",
    "# a = np.random.choice(preds.article_number.unique(), size = 1, replace = False)[0]\n",
    "aoi = 'G26535'\n",
    "a = aoi\n",
    "\n",
    "dat_a = preds[preds.article_number == a][['week', 'net_qty', 'corrected', 'y_hat']]\n",
    "        \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10,7]\n",
    "dat_a.sort_values('week').set_index('week').plot(linewidth = 3)\n",
    "dat_a.sort_values('week').set_index('week').round()\n",
    "\n",
    "dat_a[['net_qty', 'corrected', 'y_hat']].apply(np.sum).round()\n",
    "\n",
    "preds_season.reset_index()[preds_season.index == a]\n",
    "\n",
    "dat_aoi = dat0[dat0.article_number == aoi].copy()\n",
    "\n",
    "dat_aoi = pd.merge(\n",
    "    pd.DataFrame(dat_aoi.groupby(['year', 'week'])['net_qty'].sum()).reset_index(),\n",
    "    dat_aoi[['year', 'week']].drop_duplicates()\n",
    ")\n",
    "\n",
    "dat_aoi.year = [str(x) for x in dat_aoi.year]\n",
    "dat_aoi.week = [str(x) for x in dat_aoi.week]\n",
    "dat_aoi['date'] = [dt.datetime.strptime(x[0] + '-' + x[1] + '-1', \"%Y-%W-%w\") for x in zip(dat_aoi.year, dat_aoi.week)]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10,7]\n",
    "dat_aoi[['date', 'net_qty']].set_index('date').plot(linewidth = 4)\n",
    "\n",
    "# dat_aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T12:57:41.084348Z",
     "start_time": "2019-09-11T12:57:40.941795Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Overbuy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T12:49:10.530147Z",
     "start_time": "2019-10-18T12:49:10.527307Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T13:11:44.216756Z",
     "start_time": "2019-10-18T13:11:44.212799Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loss --- demand, buy, margin, cost\n",
    "def L(d, b, margin, cost):\n",
    "    if d > b:    # CANNOT satisfy demand\n",
    "        return (d - b)*margin\n",
    "    \n",
    "    elif d <= b: # CAN satisfy demand\n",
    "        return (b - d)*cost\n",
    "    \n",
    "    else:\n",
    "        print('Error')\n",
    "\n",
    "# E[L | buy, article_mean, article_sd, article_margin, article_cost]\n",
    "def EL(net_qtys, margin, cost, b):\n",
    "    return sum([L(x, b, margin, cost) for x in net_qtys])/len(net_qtys)\n",
    "\n",
    "def minimize_EL(net_qtys, margin, cost):\n",
    "    p = partial(EL, net_qtys, margin, cost) # Make EL function of only one var\n",
    "    mu = np.mean(net_qtys)\n",
    "    buy_opt = optimize.minimize_scalar(p, bounds = (mu, mu + 2*np.std(net_qtys)))\n",
    "    return int(buy_opt['x']) # optimal buy quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T13:14:07.831800Z",
     "start_time": "2019-10-18T13:14:07.828211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Profit\n",
    "def P(d, margin, cost, b):\n",
    "    if d > b:    # CANNOT satisfy demand\n",
    "        return b*margin\n",
    "    \n",
    "    elif d <= b: # CAN satisfy demand\n",
    "        return d*margin - (b - d)*cost\n",
    "    \n",
    "    else:\n",
    "        print('Error')\n",
    "\n",
    "def EP(net_qtys, margin, cost, b):\n",
    "    return -sum([P(x, margin, cost, b) for x in net_qtys])/len(net_qtys)\n",
    "\n",
    "def maximize_EP(net_qtys, margin, cost):\n",
    "    p = partial(EP, net_qtys, margin, cost) # Make EL function of only one var\n",
    "    mu = np.mean(net_qtys)\n",
    "    buy_opt = optimize.minimize_scalar(p, bounds = (mu, mu + 2*np.std(net_qtys)))\n",
    "    return int(buy_opt['x']) # optimal buy quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T13:10:45.699513Z",
     "start_time": "2019-10-18T13:10:45.544336Z"
    }
   },
   "outputs": [],
   "source": [
    "# one off e.g.s\n",
    "\n",
    "# Minimize Loss\n",
    "l = partial(EL, net_qtys, 63, 30) # Make EL function of only one var\n",
    "[print(x, ':', round(l(x))) for x in range(0, 600, 50)]\n",
    "\n",
    "# Maximize Profit\n",
    "p = partial(EP, net_qtys, 63, 30)\n",
    "[print(x, ':', round(p(x))) for x in range(0, 600, 50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T13:14:10.407922Z",
     "start_time": "2019-10-18T13:14:08.906544Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "minimize_EL(net_qtys, 63, 30)\n",
    "                          \n",
    "maximize_EP(net_qtys, 63, 30)\n",
    "\n",
    "# HUZZAH!!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T08:18:01.966364Z",
     "start_time": "2019-10-09T08:18:01.955797Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Overbuy statistics ---\n",
    "# preds_season['pct_overbuy'] = (preds_season.Opt_Ovb - preds_season.y_hat)/preds_season.y_hat*100\n",
    "# b = np.array([0, 1000, 2000, 5000, 10000, 50000])\n",
    "# preds_season['bins'] = pd.cut(preds_season.y_hat, bins = b)\n",
    "# preds_season.groupby('bins')['pct_overbuy'].describe().round()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

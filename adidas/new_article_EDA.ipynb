{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:15:21.789861Z",
     "start_time": "2019-10-24T12:15:19.553009Z"
    },
    "hideCode": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import bokeh.io\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "# init_notebook_mode()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import itertools\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "import time\n",
    "import dateutil.parser\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import gc\n",
    "import zipfile\n",
    "import sys, getopt\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from io import StringIO\n",
    "\n",
    "import dask.dataframe as dd\n",
    "#from chest import Chest\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "# Magic function to make matplotlib inline\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "import dask.dataframe as ddf\n",
    "import dask.array as da\n",
    "\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_rows', 800)\n",
    "\n",
    "import scipy\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.tsatools import detrend\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:15:57.358766Z",
     "start_time": "2019-10-24T12:15:23.306981Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat0 = pd.read_csv('data/ch4k_df.csv')\n",
    "ref_dat0 = pd.read_csv('data/Article reference data.csv', low_memory = False, error_bad_lines = False, \n",
    "                       usecols = ['article_no', 'model_no', 'art_desc', 'sports_cat_desc', 'rmh_cat_desc', \n",
    "                                  'franchise', 'gender_desc', 'age_group_desc', 'prod_grp_desc', 'prod_type_desc',\n",
    "                                  'brand_desc', 'bus_unit_desc', 'rmh_cat_desc'])\n",
    "\n",
    "# Remove clearance transactions!!\n",
    "dat0['clearance'] = dat0.clearance.fillna(0) \n",
    "dat0['net_qty'] = (1 - dat0.clearance)*dat0.net_qty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:15:59.527161Z",
     "start_time": "2019-10-24T12:15:57.360571Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = dat0.copy()\n",
    "\n",
    "# dat = dat[(dat.net_qty > 0) & (dat.season.isin(['FW15', 'FW16', 'FW17', 'FW18', 'FW19']))].round()\n",
    "\n",
    "dat = dat[(dat.net_qty > 0) & (dat.season.isin(['SS15', 'SS16', 'SS17', 'SS18', 'SS19']))].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:15:59.879503Z",
     "start_time": "2019-10-24T12:15:59.528956Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7604, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SS19 = pd.read_excel('data/ecom_SS19.xlsx').dropna()\n",
    "SS19.shape\n",
    "\n",
    "SS19 = SS19[SS19.carryover_FW18 == 'NO'] # new articles only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:16:01.273193Z",
     "start_time": "2019-10-24T12:15:59.882560Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = dat[['article_number', 'season', 'season_net_qty', 'art_desc', 'sports_cat_desc',\n",
    "           'rmh_cat_desc', 'franchise', 'gender_desc', 'age_group_desc',\n",
    "           'prod_grp_desc', 'prod_type_desc', 'price', 'margin', 'cost', 'buy_availability']].drop_duplicates()\n",
    "\n",
    "dat = dat[dat.season_net_qty > 200]\n",
    "dat[['price', 'margin', 'cost']] = dat[['price', 'margin', 'cost']] # .fillna(0).astype('int')\n",
    "\n",
    "dat = (\n",
    "    dat.\n",
    "    sort_values(['article_number', 'season']).\n",
    "    drop_duplicates(subset = 'article_number').\n",
    "    set_index('article_number').\n",
    "    dropna()\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:16:25.493520Z",
     "start_time": "2019-10-24T12:16:25.487528Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# art = np.random.choice(dat.index, size = 500, replace = False)\n",
    "\n",
    "# Just articles new in SS19, with season_net_qty > 100\n",
    "articles = set(SS19.article_number).intersection(set(dat.index))\n",
    "art = articles.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:16:01.291044Z",
     "start_time": "2019-10-24T12:16:01.284192Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3460"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# art = np.random.choice(list(articles), size = 10, replace = False)\n",
    "len(articles)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:33:01.368060Z",
     "start_time": "2019-10-24T12:16:37.802468Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations \n",
    "from itertools import combinations\n",
    "\n",
    "d = {}\n",
    "cats = ['sports_cat_desc', 'rmh_cat_desc', 'franchise', 'gender_desc', 'age_group_desc', 'prod_grp_desc', 'prod_type_desc']\n",
    "\n",
    "# Create tidy dataframe, add results to it\n",
    "\n",
    "for a in art:\n",
    "    p = dat.loc[a, 'price']\n",
    "    \n",
    "    net_qtys = pd.Series()\n",
    "    \n",
    "    dat_p = dat[(dat.price >= 0.9*p) & (dat.price <= 1.1*p)]\n",
    "    \n",
    "    for c in cats: \n",
    "        dat_a = dat_p[dat_p[c] == dat_p.loc[a, c]] # filter to that level of that category        \n",
    "        net_qtys = net_qtys.append(dat_a.season_net_qty)\n",
    "    \n",
    "    for c2 in combinations(cats, 2):\n",
    "        dat_a = dat_p[(dat_p[c2[0]] == dat_p.loc[a, c2[0]]) &\n",
    "                      (dat_p[c2[1]] == dat_p.loc[a, c2[1]])]\n",
    "        net_qtys = net_qtys.append(dat_a.season_net_qty)\n",
    "        \n",
    "    for c3 in combinations(cats, 3):\n",
    "        dat_a = dat_p[(dat_p[c3[0]] == dat_p.loc[a, c3[0]]) &\n",
    "                      (dat_p[c3[1]] == dat_p.loc[a, c3[1]]) &\n",
    "                      (dat_p[c3[2]] == dat_p.loc[a, c3[2]])]\n",
    "        net_qtys = net_qtys.append(dat_a.season_net_qty)\n",
    "    \n",
    "    for c4 in combinations(cats, 4):\n",
    "        dat_a = dat_p[(dat_p[c4[0]] == dat_p.loc[a, c4[0]]) &\n",
    "                      (dat_p[c4[1]] == dat_p.loc[a, c4[1]]) &\n",
    "                      (dat_p[c4[2]] == dat_p.loc[a, c4[2]]) &\n",
    "                      (dat_p[c4[3]] == dat_p.loc[a, c4[3]])]\n",
    "        net_qtys = net_qtys.append(dat_a.season_net_qty)\n",
    "    \n",
    "    for c4 in combinations(cats, 5):\n",
    "        dat_a = dat_p[(dat_p[c4[0]] == dat_p.loc[a, c4[0]]) &\n",
    "                      (dat_p[c4[1]] == dat_p.loc[a, c4[1]]) &\n",
    "                      (dat_p[c4[2]] == dat_p.loc[a, c4[2]]) &\n",
    "                      (dat_p[c4[3]] == dat_p.loc[a, c4[3]]) &\n",
    "                      (dat_p[c4[4]] == dat_p.loc[a, c4[4]])]\n",
    "        net_qtys = net_qtys.append(dat_a.season_net_qty)\n",
    "    \n",
    "    for c4 in combinations(cats, 6):\n",
    "        dat_a = dat_p[(dat_p[c4[0]] == dat_p.loc[a, c4[0]]) &\n",
    "                      (dat_p[c4[1]] == dat_p.loc[a, c4[1]]) &\n",
    "                      (dat_p[c4[2]] == dat_p.loc[a, c4[2]]) &\n",
    "                      (dat_p[c4[3]] == dat_p.loc[a, c4[3]]) &\n",
    "                      (dat_p[c4[4]] == dat_p.loc[a, c4[4]]) &\n",
    "                      (dat_p[c4[5]] == dat_p.loc[a, c4[5]])]\n",
    "        net_qtys = net_qtys.append(dat_a.season_net_qty)\n",
    "    \n",
    "    d[a] = {\n",
    "        'mean': net_qtys.mean(),\n",
    "        'max': net_qtys.max(),\n",
    "        '50': np.percentile(net_qtys, 50),\n",
    "        '70': np.percentile(net_qtys, 70),\n",
    "        '80': np.percentile(net_qtys, 80),\n",
    "        '90': np.percentile(net_qtys, 90),\n",
    "        'length': len(net_qtys)\n",
    "           }\n",
    "    if len(d) % 50 == 0:\n",
    "        print(len(d))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:06:11.764113Z",
     "start_time": "2019-10-24T12:06:11.756749Z"
    }
   },
   "outputs": [],
   "source": [
    "d.keys()\n",
    "d['F34164']\n",
    "d['F34164']['mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:33:37.445504Z",
     "start_time": "2019-10-24T12:33:37.437969Z"
    }
   },
   "outputs": [],
   "source": [
    "dat_art = dat[dat.index.isin(art)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:39:29.680638Z",
     "start_time": "2019-10-24T12:39:29.667089Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>pred_70</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D98181</th>\n",
       "      <td>684.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>6648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F35787</th>\n",
       "      <td>693.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>21779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DB3361</th>\n",
       "      <td>957.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>20822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BD7160</th>\n",
       "      <td>774.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DU2042</th>\n",
       "      <td>681.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>11941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean  pred_70  length\n",
       "article_number                        \n",
       "D98181          684.0    690.0    6648\n",
       "F35787          693.0    677.0   21779\n",
       "DB3361          957.0    976.0   20822\n",
       "BD7160          774.0    514.0    1165\n",
       "DU2042          681.0    565.0   11941"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.DataFrame([(a, d[a]['mean'], d[a]['70'], d[a]['length']) for a in d.keys()]).round()\n",
    "preds.columns = ('article_number', 'mean', 'pred_70', 'length')\n",
    "preds = preds.set_index('article_number')\n",
    "\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:40:13.260076Z",
     "start_time": "2019-10-24T12:40:13.250556Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat_art2 = pd.merge(\n",
    "    dat_art, \n",
    "    preds,\n",
    "    left_index=True, right_index=True,\n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "dat_art2 = dat_art2[['season', 'season_net_qty', \n",
    "                     'mean', 'pred_70',\n",
    "                     'art_desc', 'sports_cat_desc',\n",
    "       'rmh_cat_desc', 'franchise', 'gender_desc', 'age_group_desc',\n",
    "       'prod_grp_desc', 'prod_type_desc', 'price', 'margin', 'cost']] # .sort_values('APE', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:41:59.705093Z",
     "start_time": "2019-10-24T12:41:59.700551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.91040462427746"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APE = (abs(dat_art2.season_net_qty - dat_art2.pred_70)/dat_art2.season_net_qty*100).round()\n",
    "APE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T08:51:07.844164Z",
     "start_time": "2019-10-24T08:51:07.813989Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Criteria:\n",
    "# (1) in transaction data\n",
    "# (2) season_net_qty > 200 \n",
    "# (3) in eCom SS19 range file as non-carryover \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:40:51.259225Z",
     "start_time": "2019-10-24T12:40:51.245246Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat_art4 = pd.merge(\n",
    "    dat_art2, \n",
    "    SS19[['article_number', 'Ecom_FC_RMA']],\n",
    "    left_index = True, right_on = 'article_number', how = 'left'\n",
    ").drop('article_number', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:34:45.576857Z",
     "start_time": "2019-10-24T12:34:45.572930Z"
    },
    "hideCode": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Profit\n",
    "def P(d, margin, cost, b):\n",
    "    if d > b:    # CANNOT satisfy demand\n",
    "        return b*margin\n",
    "    \n",
    "    elif d <= b: # CAN satisfy demand\n",
    "        return d*margin - (b - d)*cost\n",
    "    \n",
    "    else:\n",
    "        print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:40:56.300780Z",
     "start_time": "2019-10-24T12:40:55.979308Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#P(row['season_net_qty'], row['margin'], row['cost'], row['pred'])\n",
    "\n",
    "dat_art4['eCom_profit'] = dat_art4.apply(lambda row: P(row['season_net_qty'], row['margin'], row['cost'], row['Ecom_FC_RMA']), axis=1)\n",
    "dat_art4['DAA_profit_m']  = dat_art4.apply(lambda row: P(row['season_net_qty'], row['margin'], row['cost'], row['mean']), axis=1)\n",
    "dat_art4['DAA_profit_70']  = dat_art4.apply(lambda row: P(row['season_net_qty'], row['margin'], row['cost'], row['pred_70']), axis=1)\n",
    "\n",
    "\n",
    "# for pct in ['pred', 'pred_50', 'pred_60', 'pred_70', 'pred_75', 'pred_80', 'pred_90', 'pred_98']:\n",
    "#     col = 'DAA_profit' + '_' + pct\n",
    "#     dat_art4[col]  = dat_art4.apply(lambda row: P(row['season_net_qty'], row['margin'], row['cost'], row[pct]), axis=1)\n",
    "    \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:46:44.629651Z",
     "start_time": "2019-10-24T12:46:44.621927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAA_profit_70    58465728.0\n",
       "eCom_profit      73359849.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2054794520547945"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_art4[['DAA_profit_70', 'eCom_profit']].sum()\n",
    "\n",
    "(73 - 58)/73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T13:30:49.155925Z",
     "start_time": "2019-10-21T13:30:48.981965Z"
    },
    "hideCode": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "\n",
    "plt.hist(net_qtys, bins = [0, 100, 250, 500, 750, 1000, 1250, 1500, 1750, 2000, 5000], density = True)\n",
    "\n",
    "pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T09:23:01.010037Z",
     "start_time": "2019-10-24T09:23:00.995799Z"
    },
    "hideCode": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Empirical distributions\n",
    "\n",
    "import numpy as np\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "ecdf = ECDF(net_qtys)\n",
    "\n",
    "ecdf([100, 500, 1000, 3000])\n",
    "\n",
    "np.percentile(net_qtys, 75)\n",
    "net_qtys.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T11:06:12.348050Z",
     "start_time": "2019-10-08T11:06:12.077536Z"
    },
    "hideCode": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---- Plot -----\n",
    "# a = np.random.choice(preds.article_number.unique(), size = 1, replace = False)[0]\n",
    "aoi = 'G26535'\n",
    "a = aoi\n",
    "\n",
    "dat_a = preds[preds.article_number == a][['week', 'net_qty', 'corrected', 'y_hat']]\n",
    "        \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10,7]\n",
    "dat_a.sort_values('week').set_index('week').plot(linewidth = 3)\n",
    "dat_a.sort_values('week').set_index('week').round()\n",
    "\n",
    "dat_a[['net_qty', 'corrected', 'y_hat']].apply(np.sum).round()\n",
    "\n",
    "preds_season.reset_index()[preds_season.index == a]\n",
    "\n",
    "dat_aoi = dat0[dat0.article_number == aoi].copy()\n",
    "\n",
    "dat_aoi = pd.merge(\n",
    "    pd.DataFrame(dat_aoi.groupby(['year', 'week'])['net_qty'].sum()).reset_index(),\n",
    "    dat_aoi[['year', 'week']].drop_duplicates()\n",
    ")\n",
    "\n",
    "dat_aoi.year = [str(x) for x in dat_aoi.year]\n",
    "dat_aoi.week = [str(x) for x in dat_aoi.week]\n",
    "dat_aoi['date'] = [dt.datetime.strptime(x[0] + '-' + x[1] + '-1', \"%Y-%W-%w\") for x in zip(dat_aoi.year, dat_aoi.week)]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10,7]\n",
    "dat_aoi[['date', 'net_qty']].set_index('date').plot(linewidth = 4)\n",
    "\n",
    "# dat_aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T12:57:41.084348Z",
     "start_time": "2019-09-11T12:57:40.941795Z"
    },
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Optimal Buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T13:31:14.727324Z",
     "start_time": "2019-10-21T13:31:10.341247Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat[dat.index == art[0]][['season', 'season_net_qty', 'sports_cat_desc', 'rmh_cat_desc', 'franchise', 'price', 'margin', 'cost']]\n",
    "\n",
    "minimize_EL(net_qtys, dat.loc[a, 'margin'], dat.loc[a, 'cost'])\n",
    "net_qtys.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T12:49:10.530147Z",
     "start_time": "2019-10-18T12:49:10.527307Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T12:34:58.348197Z",
     "start_time": "2019-10-21T12:34:58.342648Z"
    },
    "hideCode": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loss --- demand, buy, margin, cost\n",
    "def L(d, b, margin, cost):\n",
    "    if d > b:    # CANNOT satisfy demand\n",
    "        return (d - b)*margin\n",
    "    \n",
    "    elif d <= b: # CAN satisfy demand\n",
    "        return (b - d)*cost\n",
    "    \n",
    "    else:\n",
    "        print('Error')\n",
    "\n",
    "# E[L | buy, article_mean, article_sd, article_margin, article_cost]\n",
    "def EL(net_qtys, margin, cost, b):\n",
    "    return sum([L(x, b, margin, cost) for x in net_qtys])/len(net_qtys)\n",
    "\n",
    "def minimize_EL(net_qtys, margin, cost):\n",
    "    p = partial(EL, net_qtys, margin, cost) # Make EL function of only one var\n",
    "    mu = np.mean(net_qtys)\n",
    "    buy_opt = optimize.minimize_scalar(p, bounds = (mu, mu + 2*np.std(net_qtys)))\n",
    "    return int(buy_opt['x']) # optimal buy quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T12:34:58.680023Z",
     "start_time": "2019-10-21T12:34:58.674169Z"
    },
    "hideCode": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Profit\n",
    "def P(d, margin, cost, b):\n",
    "    if d > b:    # CANNOT satisfy demand\n",
    "        return b*margin\n",
    "    \n",
    "    elif d <= b: # CAN satisfy demand\n",
    "        return d*margin - (b - d)*cost\n",
    "    \n",
    "    else:\n",
    "        print('Error')\n",
    "\n",
    "def EP(net_qtys, margin, cost, b):\n",
    "    return -sum([P(x, margin, cost, b) for x in net_qtys])Yeah /len(net_qtys) # integral--by rectangle method, each w/ 1/n height\n",
    "\n",
    "def maximize_EP(net_qtys, margin, cost):\n",
    "    p = partial(EP, net_qtys, margin, cost) # Make EL function of only one var\n",
    "    mu = np.mean(net_qtys)\n",
    "    buy_opt = optimize.minimize_scalar(p, bounds = (mu, mu + 2*np.std(net_qtys)))\n",
    "    return int(buy_opt['x']) # optimal buy quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T13:21:49.823150Z",
     "start_time": "2019-10-21T13:21:49.537691Z"
    },
    "hideCode": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one offs\n",
    "\n",
    "# # Minimize Loss\n",
    "# l = partial(EL, net_qtys, 63, 30) # Make EL function of only one var\n",
    "# [print(x, ':', round(l(x))) for x in range(0, 600, 50)]\n",
    "\n",
    "# # Maximize Profit\n",
    "# p = partial(EP, net_qtys, 63, 30)\n",
    "# [print(x, ':', round(p(x))) for x in range(0, 600, 50)]\n",
    "\n",
    "\n",
    "minimize_EL(net_qtys, 6, 2)\n",
    "                          \n",
    "maximize_EP(net_qtys, 6, 2)\n",
    "\n",
    "# HUZZAH!!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T08:18:01.966364Z",
     "start_time": "2019-10-09T08:18:01.955797Z"
    },
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Overbuy statistics ---\n",
    "# preds_season['pct_overbuy'] = (preds_season.Opt_Ovb - preds_season.y_hat)/preds_season.y_hat*100\n",
    "# b = np.array([0, 1000, 2000, 5000, 10000, 50000])\n",
    "# preds_season['bins'] = pd.cut(preds_season.y_hat, bins = b)\n",
    "# preds_season.groupby('bins')['pct_overbuy'].describe().round()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T11:54:54.157177Z",
     "start_time": "2019-10-24T11:54:54.147475Z"
    }
   },
   "outputs": [],
   "source": [
    "dat_art5[dat_art5.pred_90 < dat_art5.season_net_qty].sum()\n",
    "\n",
    "# season_net_qty         227889.0\n",
    "# pred_80                129573.0\n",
    "# Ecom_FC_RMA            252412.0\n",
    "# DAA_profit_pred_80    4725638.0\n",
    "# eCom_profit           6433454.0\n",
    "# diff                  2266284.0\n",
    "# dtype: float64\n",
    "\n",
    "# Comments: \n",
    "    # when we under-forecast... we DRAMATICALLY under-forecast\n",
    "    # HUGE difference in profit\n",
    "\n",
    "dat_art5[dat_art5.pred_90 >= dat_art5.season_net_qty].sum()\n",
    "\n",
    "# season_net_qty         179877.0\n",
    "# pred_80                354269.0\n",
    "# Ecom_FC_RMA            310015.0\n",
    "# DAA_profit_pred_80    4232213.0\n",
    "# eCom_profit           4550809.0\n",
    "# diff                  2017816.0\n",
    "# dtype: float64\n",
    "\n",
    "# Comments: \n",
    "    # in sum, we just slightly over-forecast\n",
    "    # Tiny difference in profit\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

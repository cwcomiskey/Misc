{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T12:55:33.847576Z",
     "start_time": "2019-12-19T12:55:33.047095Z"
    },
    "code_folding": [
     0
    ],
    "hideCode": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modules, functions -- \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "# import multiprocessing\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import bokeh\n",
    "# import bokeh.io\n",
    "# from bokeh.plotting import figure\n",
    "# from bokeh.io import output_notebook, show\n",
    "\n",
    "# init_notebook_mode()\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# import re\n",
    "# import math\n",
    "# import copy\n",
    "\n",
    "# from collections import defaultdict\n",
    "# import csv\n",
    "# import itertools\n",
    "# import datetime \n",
    "# from datetime import datetime\n",
    "# import time\n",
    "# import dateutil.parser\n",
    "# import pickle\n",
    "# import random\n",
    "\n",
    "# import gc\n",
    "# import zipfile\n",
    "# import sys, getopt\n",
    "# import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from io import StringIO\n",
    "\n",
    "# import dask.dataframe as dd\n",
    "#from chest import Chest\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "# Magic function to make matplotlib inline\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# Set up Bokeh for inline viewing\n",
    "# bokeh.io.output_notebook()\n",
    "\n",
    "# import dask.dataframe as ddf\n",
    "# import dask.array as da\n",
    "\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_rows', 1700)\n",
    "\n",
    "# import scipy\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# from statsmodels.tsa.tsatools import detrend\n",
    "\n",
    "# import datetime as dt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import functions as fcns # custom functions Artem/Chris wrote\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # adidas v rbk\n",
    "# from pandas import DataFrame, Series\n",
    "# fw20['brand'].value_counts()\n",
    "\n",
    "# # Carryover coverage\n",
    "# fw20['rev'] = fw20.price * fw20.eCom_RMA1\n",
    "# fw20.groupby('brand')['rev'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hideCode": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # DAVID OOP code\n",
    "\n",
    "# # Function Definitions\n",
    "\n",
    "# class parameters():\n",
    "#     def __init__(self, param_array):\n",
    "#         self.alpha = param_array[0]\n",
    "#         self.beta = param_array[1]\n",
    "#         self.omega = param_array[2] / (1-self.beta) # one way to choose that is omega/(1-beta) = uncoMnditional mean\n",
    "#         self.sigma = param_array[3]\n",
    "#         self.f0 = param_array[4] # one way to choose is unconditional mean\n",
    "\n",
    "# def loglik(x, y, f, sigma):\n",
    "#     ll = -1/2*np.log(2*np.pi ) - 1/2*np.log(sigma) - 1/(2*sigma)*(y - x*f)**2\n",
    "#     return ll\n",
    "\n",
    "# def score_compute(x, y, f, sigma):\n",
    "#     return (y - x*f)/sigma\n",
    "\n",
    "# def score_compute_2(x, y, f, sigma=None):\n",
    "#     return(y - x*f) # ** The 'type = 2' modification **\n",
    "\n",
    "# def filterGAS(p, x, y, score_fun):\n",
    "#     score0 = score_fun(x[0,:], y[0,:],p.f0, p.sigma)\n",
    "#     f = np.zeros((len(y),1))\n",
    "#     f[0,:] = p.f0\n",
    "#     for t in range(1,len(y)):\n",
    "#         scoret = score_fun(x[t-1,:], y[t-1,:], f[t-1,:], p.sigma)\n",
    "#         f[t,:] = p.omega + p.alpha*scoret + p.beta*f[t-1,:]\n",
    "#     return f\n",
    "\n",
    "\n",
    "# def loglikest(params, x, y, score_fun):\n",
    "#     p = parameters(params)\n",
    "#     f = filterGAS(p, x, y, score_fun)\n",
    "#     ll = np.zeros((len(y), 1))\n",
    "#     m = len(y)\n",
    "#     for t in range(0, len(y)):\n",
    "#         ll[t,:] = loglik(x[t,:], y[t,:], f[t,:], p.sigma)\n",
    "#     loglik_res = -(np.sum(ll))/m\n",
    "#     return loglik_res\n",
    "\n",
    "\n",
    "# def GAS_optimize(x, y, score_fun, marker_str):\n",
    "#     return scipy.optimize.minimize(\n",
    "#        loglikest,                              # function to minimize (log likelihood y|x,theta)\n",
    "#        np.array([0.8, 0.9, np.mean(y), 1, np.mean(y)]), # initial parameter values (starting)\n",
    "#        args=(x, y, score_fun),\n",
    "#        options ={'eps':1e-09, 'maxiter': 600, 'ftol': 1e-12}, # TODO pass as parameter or create config file\n",
    "#        method='L-BFGS-B',\n",
    "#        bounds=((0,  None),             # alpha\n",
    "#                (-1, 1),                # beta\n",
    "#                (0.001, np.mean(y)*2),  # omega\n",
    "#                (0.001, None),          # sigma\n",
    "#                (0.001, np.mean(y)*2)   # f\n",
    "#               )\n",
    "#        )\n",
    "\n",
    "\n",
    "\n",
    "# def GAS_est(df):\n",
    "#     \"\"\" <High level description of function>\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     df : pandas DataFrame\n",
    "#        <Description>\n",
    "#     Returns\n",
    "#     -------\n",
    "#     ret: pandas DataFrame\n",
    "#        <Description>\n",
    "#     Raises\n",
    "#     ------\n",
    "#     (List and description of specific errors generated and thrown based on intenal function requirements)\n",
    "#     OtherError when an other error\n",
    "#     \"\"\"\n",
    "#     y = df.net_qty.values.reshape(-1,1)          # observed demand (response)\n",
    "#     x = df.buy_availability.values.reshape(-1,1)   # buy_availability (explanatory)\n",
    "    \n",
    "#     ret = pd.DataFrame()\n",
    "#     ret[['year','week']] = df[['year','week']]\n",
    "    \n",
    "#     score_fun = score_compute\n",
    "#     marker_str = 'One'\n",
    "    \n",
    "#     opt_result = GAS_optimize(x, y, score_fun, marker_str)\n",
    "    \n",
    "#     if opt_result.success == False:\n",
    "#         score_fun= score_compute_2\n",
    "#         marker_str = 'Two'\n",
    "#         opt_result = GAS_optimize(x, y, score_fun, marker_str)\n",
    "        \n",
    "#     x1par = parameters(opt_result.x)\n",
    "#     GAS = filterGAS(x1par, x, y, score_fun)\n",
    "    \n",
    "#     ret['GAS_est'] = GAS\n",
    "#     ret['Convergence'] = [opt_result.success] * len(y)\n",
    "#     ret['Convg type'] = [marker_str] * len(y)\n",
    "    \n",
    "#     return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hideCode": true,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# April articles\n",
    "\n",
    "aas = ['DV1549', 'EE1152', 'DV1508', 'ED6024', 'CY4574', 'ED9384', 'BK7345', 'DV2400', 'DH5798']\n",
    "\n",
    "# aoi = 'DV1549'\n",
    "# a = aoi\n",
    "\n",
    "preds_aa = (preds[preds.article_number.isin(aas)][['article_number', 'week', 'net_qty', 'GAS_est', 'seas_preds', 'y_hat']].\n",
    "            sort_values(['article_number', 'week']).\n",
    "            set_index('week')).round()\n",
    "        \n",
    "\n",
    "preds_aa[preds_aa.article_number == 'DV1549']\n",
    "\n",
    "pred_aggs_aa = preds_aa.groupby('article_number')[['net_qty', 'GAS_est', 'seas_preds', 'y_hat']].apply(sum).round()\n",
    "\n",
    "\n",
    "\n",
    "for c in pred_aggs_aa.columns:\n",
    "    if type(pred_aggs_aa[c][1]) == np.float64:\n",
    "        pred_aggs_aa[c] = pred_aggs_aa[c].fillna(0).astype(int)\n",
    "\n",
    "pred_aggs_aa[~np.isnan(pred_aggs_aa.GAS_est)].loc[aas[i-1], 'y_hat'].sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(25,32)); # width, height\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.2); # vertical spacing, horizontal spacing\n",
    "for i in range(1, 10):\n",
    "    ax = fig.add_subplot(5, 2, i, )\n",
    "    preds_ax = preds_aa[preds_aa.article_number == aas[i-1]]\n",
    "    ax.plot(preds_ax.index, preds_ax['net_qty'], linewidth=4.5, label = 'Observed net_qty')\n",
    "    ax.plot(preds_ax.index, preds_ax['y_hat'], linewidth=4.5, label = 'Model net_qty estimate')\n",
    "    ax.set_title('Article: ' + aas[i-1] + \n",
    "                 ' \\n net_qty STD: ' + str(pred_aggs_aa.loc[aas[i-1], 'net_qty']) + \n",
    "                 ' \\n Full availability estimate STD: ' + str(preds_aa[(~np.isnan(preds_aa.GAS_est)) & (preds_aa.article_number == aas[i-1])].y_hat.sum().astype(int)) +\n",
    "                 ' \\n FW19 full season estimate: ' + str(pred_aggs_aa.loc[aas[i-1], 'y_hat']), \n",
    "                 fontsize=16)\n",
    "    ax.legend()\n",
    "\n",
    "fig.savefig('aa_fig.png')    \n",
    "\n",
    "pass;\n",
    "\n",
    "\n",
    "\n",
    "preds_aa[['GAS_est', 'net_qty', 'seas_preds']].apply(np.sum).round()\n",
    "\n",
    "preds_season.reset_index()[preds_season.index.isin(aas)]\n",
    "\n",
    "dat_aa = dat0[dat0.article_number.isin(aas)].copy()\n",
    "\n",
    "dat_aa = pd.merge(\n",
    "    pd.DataFrame(dat_aa.groupby(['year', 'week'])['net_qty'].sum()).reset_index(),\n",
    "    dat_aa[['year', 'week']].drop_duplicates()\n",
    ")\n",
    "\n",
    "dat_aa.year = [str(x) for x in dat_aa.year]\n",
    "dat_aa.week = [str(x) for x in dat_aa.week]\n",
    "dat_aa['date'] = [dt.datetime.strptime(x[0] + '-' + x[1] + '-1', \"%Y-%W-%w\") for x in zip(dat_aa.year, dat_aa.week)]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10,7]\n",
    "dat_aa[['date', 'net_qty']].set_index('date').plot(linewidth = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ----- For demo ------\n",
    "\n",
    "fcsts = preds_season.copy()\n",
    "\n",
    "# fcsts = pd.read_excel('data/FW20_forecasts.xlsx') # adidas RMA2 -- 21 October\n",
    "\n",
    "\n",
    "fcsts.loc[:, 'impact'] = fcsts.apply(lambda row: np.where(row['buy_recommendation'] > row['eCom_ILS1'], \n",
    "                                                         (row['buy_recommendation'] - row['eCom_ILS1']) * row['margin'], \n",
    "                                                         (row['eCom_ILS1'] - row['buy_recommendation']) * row['cost']), axis = 1)\n",
    "\n",
    "fcsts = fcsts.sort_values('impact', ascending = False).round()\n",
    "\n",
    "fcsts = fcsts[['net_forecast', 'buy_recommendation', 'eCom_ILS1', 'impact', 'brand', 'description', 'type', 'BU', 'RMH', 'price', 'cost', 'margin',  'FW19_total_market_FC', 'notes']]\n",
    "\n",
    "\n",
    "fcsts.head()\n",
    "\n",
    "preds[preds.article_number == 'CG6708'].head()\n",
    "dat0[dat0.article_number == 'CG6708'].head()\n",
    "\n",
    "# EDA Plots\n",
    "\n",
    "# ---- Plot -----\n",
    "aoi = 'F34314'\n",
    "a = aoi\n",
    "\n",
    "# -------\n",
    "\n",
    "dat_a = preds[preds.article_number == a][['week', 'net_qty', 'GAS_est', 'y_hat']]\n",
    "dat_a['year'] = '2019'\n",
    "dat_a.week = [str(x) for x in dat_a.week]\n",
    "dat_a['date'] = [dt.datetime.strptime(x[0] + '-' + x[1] + '-1', \"%Y-%W-%w\") for x in zip(dat_a.year, dat_a.week)]\n",
    "\n",
    "# -------\n",
    "\n",
    "print('This season:')\n",
    "print(dat_a[['net_qty', 'GAS_est', 'y_hat']].apply(np.sum).round())\n",
    "\n",
    "dat_aoi = dat0[dat0.article_number == aoi].copy()\n",
    "\n",
    "dat_aoi = pd.merge(pd.DataFrame(dat_aoi.groupby(['year', 'week'])['net_qty'].sum()).reset_index(),dat_aoi[['year', 'week']].drop_duplicates())\n",
    "dat_aoi.year = [str(x) for x in dat_aoi.year]\n",
    "dat_aoi.week = [str(x) for x in dat_aoi.week]\n",
    "dat_aoi['date'] = [dt.datetime.strptime(x[0] + '-' + x[1] + '-1', \"%Y-%W-%w\") for x in zip(dat_aoi.year, dat_aoi.week)]\n",
    "\n",
    "# --------\n",
    "\n",
    "full = pd.merge(dat_a, dat_aoi, how = 'outer').sort_values('date').set_index('date')\n",
    "\n",
    "full = full[~((full.index > dt.datetime(2019, 5, 27))  & full.y_hat.isna())]\n",
    "# full = full.drop_duplicates(subset = ['week'], keep = 'last')\n",
    "\n",
    "full = full.rename(columns = {'y_hat': 'model net_qty'})\n",
    "\n",
    "# --------\n",
    "\n",
    "full.loc[dt.datetime(2019, 11, 4), 'net_qty'] = np.nan # manually change entry\n",
    "\n",
    "full # ************\n",
    "\n",
    "# ----\n",
    "plt.rcParams[\"figure.figsize\"] = [20,8]\n",
    "full.drop('GAS_est', axis = 1).plot(linewidth = 3)\n",
    "plt.ylabel('net_qty')\n",
    "plt.title('Article net_qty: ' + aoi)\n",
    "\n",
    "# -------\n",
    "\n",
    "fcsts[fcsts.index == aoi]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# dat_GAS_a = np.random.choice(dat_GAS.article_number.unique(), size = 100, replace = False)\n",
    "# dat_GAS = dat_GAS[dat_GAS.article_number.isin(dat_GAS_a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# impact evaluations -- \n",
    "\n",
    "rma2_adi['rev'] = rma2_adi['Sum of WE eCom'] * rma2_adi['Market Retail Price']\n",
    "\n",
    "rma2_adi['carryover'] = rma2_adi['Article Number'].isin(carryovers)\n",
    "\n",
    "print('Total range: ', len(rma2_adi['Article Number'].unique()))\n",
    "rma2_adi.head()\n",
    "rma2_adi.carryover.value_counts() # non/carryover\n",
    "\n",
    "# Revenue total\n",
    "rma2_adi.rev.sum()\n",
    "rma2_adi.groupby('carryover')['rev'].sum().round()\n",
    "\n",
    "rbk_carryovers = carryovers.union(addtl_classics)\n",
    "\n",
    "rma2_rbk['rev'] = rma2_rbk['RBK WE eCom'] * rma2_rbk['Hub Retail Price']\n",
    "\n",
    "rma2_rbk['carryover'] = rma2_rbk['Article Number'].isin(rbk_carryovers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Overbuy statistics ---\n",
    "# preds_season['pct_overbuy'] = (preds_season.Opt_Ovb - preds_season.y_hat)/preds_season.y_hat*100\n",
    "# b = np.array([0, 1000, 2000, 5000, 10000, 50000])\n",
    "# preds_season['bins'] = pd.cut(preds_season.y_hat, bins = b)\n",
    "# preds_season.groupby('bins')['pct_overbuy'].describe().round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Magnifying glass -- \n",
    "aoi = 'G27706'\n",
    "a = aoi\n",
    "\n",
    "#dat0[dat0.article_number == aoi].sort_values(['country', 'year', 'week'])#.iloc[1,]\n",
    "\n",
    "\n",
    "preds_season[preds_season.article_number == a]\n",
    "\n",
    "dat_a = preds[preds.article_number == a]\n",
    "dat_a.sort_values(['year', 'week']).set_index(['year', 'week']).drop('article_number', axis = 1).apply(np.sum)\n",
    "\n",
    "dat_a[~dat_a.net_qty.isna()]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10,7]\n",
    "dat_a.sort_values(['year', 'week']).set_index(['year', 'week']).plot(linewidth = 3)\n",
    "\n",
    "dat_a.sort_values(['year', 'week']).set_index(['year', 'week'])\n",
    "\n",
    "# dat0[dat0.article_number == aoi].sort_values(['country', 'year', 'week'])#.iloc[1,]\n",
    "\n",
    "# plot -- \n",
    "dat_aoi = dat0[dat0.article_number == aoi].copy()\n",
    "dat_aoi = pd.merge(pd.DataFrame(dat_aoi.groupby(['year', 'week'])['net_qty'].sum()).reset_index(), dat_aoi[['year', 'week']].drop_duplicates())\n",
    "dat_aoi.year = [str(x) for x in dat_aoi.year]\n",
    "dat_aoi.week = [str(x) for x in dat_aoi.week]\n",
    "dat_aoi['date'] = [dt.datetime.strptime(x[0] + '-' + x[1] + '-1', \"%Y-%W-%w\") for x in zip(dat_aoi.year, dat_aoi.week)]\n",
    "plt.rcParams[\"figure.figsize\"] = [10,7]\n",
    "dat_aoi[['date', 'net_qty']].set_index('date').plot(linewidth = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# # ------------ Stealth carryovers (DEPRECATED) ----------------\n",
    "\n",
    "# carryovers.intersection(['EE6147', 'B22716', 'EE6145', 'EE6146'])\n",
    "# carryovers.intersection(['FW5947', 'FV5946', 'FV5943', 'FV5943'])\n",
    "\n",
    "\n",
    "\n",
    "# # all -- \n",
    "\n",
    "# stealth = pd.read_csv('data/stealth_carryovers_FW2020.csv', low_memory = False, error_bad_lines = False, sep = \";\")\n",
    "\n",
    "# # stealth2 = pd.read_csv('data/stealth_carryovers_eu_RMA2.csv').rename(columns = {'article1': 'article', 'article2': 'stealth_article'})\n",
    "# # stealth3 = pd.concat([stealth, stealth2])\n",
    "\n",
    "# FW19_range = buyer_table.article_number.unique()\n",
    "# FW20_range = set(rma2_adi['Article Number']).union(set(rma2_rbk['Article Number']))\n",
    "\n",
    "# # New forecasts: IN FW20 --- NOT IN FW19\n",
    "# additions = stealth[(stealth.article.isin(FW20_range)) & (~(stealth.article.isin(carryovers)))] \n",
    "\n",
    "# find_me = additions.stealth_article\n",
    "\n",
    "# dat_stealth = dat0[(dat0.article_number.isin(['BB9103', 'BB9104'])) & (dat0.season.isin(['FW18', 'FW17', 'FW16', 'FW15']))].copy()\n",
    "\n",
    "# dat_stealth = dat_stealth[['article_number', 'year', 'week', 'country', 'season', 'net_qty', 'buy_availability']].sort_values(['article_number', 'country', 'year', 'week'])\n",
    "\n",
    "# # GAS step\n",
    "\n",
    "# dat_GAS_stealth = dat_stealth.groupby(['article_number', 'country']).apply(GAS_est).reset_index()\n",
    "# dat_GAS_stealth = pd.DataFrame(dat_GAS_stealth.groupby(['article_number', 'year', 'week'])['GAS_est'].sum()).reset_index()\n",
    "\n",
    "# # SEASONALITY step\n",
    "# seasonality_dat_stealth = (dat0[dat0.article_number.isin(['BB9103', 'BB9104'])].\n",
    "#     copy()[['article_number', 'year', 'week', 'country', 'season', 'net_qty', \n",
    "#             'sports_cat_desc', 'rmh_cat_desc', 'gender_desc', \n",
    "#             'age_group_desc', 'franchise', 'prod_grp_desc']].\n",
    "#     dropna().sort_values(['article_number', 'year', 'week'])\n",
    "#                   )\n",
    "\n",
    "# # -- Sum over UK/EU, ADD article reference data --\n",
    "# seasonality_dat_stealth = pd.merge(\n",
    "#     pd.DataFrame(seasonality_dat_stealth.groupby(['article_number', 'season', 'year', 'week'])['net_qty'].sum()).reset_index(), # sum over UK & EU\n",
    "#     seasonality_dat_stealth[['article_number', 'sports_cat_desc', 'rmh_cat_desc', 'gender_desc', 'age_group_desc', 'franchise', 'prod_grp_desc']].drop_duplicates() # add reference information\n",
    "#     ).dropna().sort_values(['article_number', 'year', 'week'])\n",
    "\n",
    "# seasonality_dat_stealth = seasonality_dat_stealth[seasonality_dat_stealth.season == 'FW18']\n",
    "\n",
    "# preds_stealth = seasonality_dat_stealth.groupby(['article_number']).apply(regress).reset_index()\n",
    "\n",
    "# # Merge back with reference data\n",
    "# preds_stealth = pd.merge(\n",
    "#     preds_stealth,\n",
    "#     seasonality_dat_stealth[seasonality_dat_stealth.season == 'FW18'],\n",
    "#     how = 'left').sort_values(['article_number', 'year', 'week'])[['article_number', 'year', 'week', 'net_qty', 'seas_preds']] # .fillna(method='ffill')\n",
    "\n",
    "\n",
    "# # Zero out negative preds\n",
    "# preds_stealth['seas_preds'] = np.where(preds_stealth.seas_preds > 0, preds_stealth.seas_preds, 0) \n",
    "\n",
    "\n",
    "\n",
    "# # Combined observed weeks (partial season)  --- AND --- regression predicted (all) weeks\n",
    "# preds_stealth = pd.merge(\n",
    "#     preds_stealth,   # all weeks\n",
    "#     dat_GAS_stealth, # observed weeks\n",
    "#     how = 'left')\n",
    "\n",
    "\n",
    "\n",
    "# # weekly assignment of GAS, seasonality, or combination\n",
    "# preds_stealth['y_hat'] = np.where(np.isnan(preds_stealth.GAS_est), preds_stealth.seas_preds, (preds_stealth.GAS_est + preds_stealth.seas_preds)/2)\n",
    "\n",
    "\n",
    "\n",
    "# # Sum over season\n",
    "# preds_season_stealth = pd.DataFrame(preds_stealth.groupby('article_number')['y_hat'].apply(sum).round())\n",
    "\n",
    "\n",
    "\n",
    "# # Growth\n",
    "# preds_season_stealth['y_hat'] = preds_season_stealth.y_hat # * 1.1 # default growth rate\n",
    "\n",
    "# # Match stealth to its carryover\n",
    "# preds_season_stealth = pd.merge(\n",
    "#     preds_season_stealth,\n",
    "#     additions,\n",
    "#     how = 'left', left_index = True, right_on = 'stealth_article'\n",
    "# ).drop('stealth_article', axis = 1).rename(columns = {'article': 'article_number'}).set_index('article_number')\n",
    "\n",
    "# # Combine DAA + eCom\n",
    "# preds_season_stealth = pd.merge(\n",
    "#     preds_season_stealth.reset_index(),  # DAA forecasts\n",
    "#     rma2,                                # eCom RMA2 forecast\n",
    "#     how = 'left', left_on='article_number', right_on='Article Number'\n",
    "# ).drop('Article Number', axis = 1).round()\n",
    "\n",
    "# # add price/cost for optimal overbuy\n",
    "# preds_season_stealth = pd.merge(preds_season_stealth, cost_margin, how = 'left', left_on = 'article_number', right_index=True).round()\n",
    "\n",
    "\n",
    "\n",
    "# # see evaluation.ipynb for sd estimation \n",
    "\n",
    "# opt_ovb_stealth = pd.DataFrame(preds_season_stealth.\n",
    "#                            apply(lambda row: minimize_EL(row['y_hat'], 550 + 0.2*row['y_hat'], row['margin'], row['cost']), axis=1)\n",
    "#                           )\n",
    "\n",
    "# opt_ovb_stealth = opt_ovb_stealth.rename(columns = {opt_ovb_stealth.columns[0]: 'Opt_Ovb'})\n",
    "\n",
    "# # Combine with data\n",
    "# preds_season_stealth = pd.merge(\n",
    "#     preds_season_stealth, # everything\n",
    "#     opt_ovb_stealth,      # optimal overbuy\n",
    "#     right_index= True, left_index= True\n",
    "# )\n",
    "\n",
    "# # IMPACT\n",
    "# # preds_season_stealth['impact'] = preds_season_stealth.apply(lambda row: np.abs(row['y_hat'] - row['WE eCom'])*(row['cost'] + row['margin']), axis = 1).round()                                                \n",
    "# # preds_season_stealth = preds_season_stealth.sort_values('impact', ascending = False).round()\n",
    "             \n",
    "# # Reorder for concatenating\n",
    "# preds_season_stealth = preds_season_stealth[['article_number', 'y_hat', 'WE eCom', 'price', 'cost', 'margin', 'Opt_Ovb']]\n",
    "                                            \n",
    "                                            \n",
    "                                            \n",
    "\n",
    "# # Combine stealth with the rest\n",
    "\n",
    "# preds_season = pd.concat([preds_season, preds_season_stealth], sort=True)[['article_number', 'y_hat', 'WE eCom', 'price', 'cost', 'margin', 'Opt_Ovb']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Managing 'inclusive' irregularities -- \n",
    "\n",
    "# preds_season.loc[:, 'impact'] = preds_season.apply(lambda row: np.abs(row['net_forecast'] - row['eCom_ILS1'])*(row['cost'] + row['margin']), axis = 1).round()                                                \n",
    "             \n",
    "# preds_season_all = pd.read_excel('data/preds_season_all.xlsx').drop('Unnamed: 0', axis = 1).rename(columns = {'y_hat': 'net_forecast_incl_clearance', 'Opt_Ovb': 'buy_rec_incl_clearance'})\n",
    "\n",
    "\n",
    "# preds_season.shape\n",
    "\n",
    "# preds_season_both = pd.merge(preds_season, preds_season_all[['article_number', 'net_forecast_incl_clearance', 'buy_rec_incl_clearance']], how = 'left')\n",
    "\n",
    "# preds_season_both = preds_season_both[['article_number', 'brand', 'model_no', 'description', 'type', 'BU', 'RMH', 'price', 'cost', 'margin', \n",
    "#                                        'net_forecast', 'buy_recommendation', 'net_forecast_incl_clearance', 'buy_rec_incl_clearance', 'eCom_ILS1', # 'pct_difference',\n",
    "#                                        'FW19_total_market_FC', 'FW19_total_ecom_SO', 'FW19_total_ecom_RDP']].set_index('article_number')\n",
    "\n",
    "# preds_season_both['buy_rec_incl_clearance'] = np.where(preds_season_both['buy_rec_incl_clearance'] > preds_season_both['buy_recommendation'], preds_season_both['buy_rec_incl_clearance'], preds_season_both['buy_recommendation'])\n",
    "# preds_season_both['net_forecast_incl_clearance'] = np.where(preds_season_both['net_forecast_incl_clearance'] > preds_season_both['net_forecast'], preds_season_both['net_forecast_incl_clearance'], preds_season_both['net_forecast'])\n",
    "\n",
    "# # Convert to integers to remove '.0' endings\n",
    "# for c in preds_season_both.columns:\n",
    "#     if type(preds_season_both[c][1]) == np.float64:\n",
    "#         preds_season_both.loc[:, c] = preds_season_both[c].fillna(0).replace(np.inf, 0).astype(int)\n",
    "\n",
    "\n",
    "# preds_season_both = preds_season_both[~preds_season_both.index.isin(unreliable)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Add column with # of observed weeks\n",
    "\n",
    "# ab = pd.DataFrame(\n",
    "#     preds[(~preds.net_qty.isna()) & (preds.net_qty > 0)].\n",
    "#     article_number.value_counts()).rename(columns = {'article_number': 'week_count'})\n",
    "    \n",
    "# preds_season = pd.merge(preds_season, ab, how = 'left', left_on='article_number', right_index = True)\n",
    "\n",
    "# # Retain articles with at least 4 observed weeks\n",
    "# preds_season = preds_season[(preds_season.week_count > 3) & (preds_season.net_qty > 40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Investigate w/ one article focus\n",
    "\n",
    "dat0 = pd.read_csv('data/ch4k.csv')\n",
    "ref_dat0 = pd.read_csv('data/Article reference data.csv', low_memory = False, error_bad_lines = False, \n",
    "                       usecols = ['article_no', 'model_no', 'art_desc', 'sports_cat_desc', 'rmh_cat_desc', \n",
    "                                  'franchise', 'gender_desc', 'age_group_desc', 'prod_grp_desc', 'prod_type_desc',\n",
    "                                  'brand_desc', 'bus_unit_desc', 'rmh_cat_desc'])\n",
    "\n",
    "# All transactions\n",
    "dat_all = dat0.copy()\n",
    "\n",
    "# Non-clearance transactions\n",
    "\n",
    "# dat = dat0.copy()\n",
    "# dat['clearance'] = dat.clearance.fillna(0) \n",
    "# dat['net_qty'] = (1 - dat.clearance)*dat.net_qty\n",
    "\n",
    "aoi = 'EE7570'\n",
    "\n",
    "#dat_eda = dat[(dat.article_number.isin([aoi])) & (dat.season.isin(['FW19', 'FW18', 'FW17', 'FW16', 'FW15']))].copy()\n",
    "dat_eda = dat_all[(dat_all.article_number.isin([aoi])) & (dat_all.season.isin(['FW19', 'FW18', 'FW17', 'FW16', 'FW15']))].copy()\n",
    "\n",
    "dat_eda = dat_eda[['article_number', 'year', 'week', 'country', 'season', 'net_qty', 'buy_availability']].sort_values(['article_number', 'country', 'year', 'week'])\n",
    "\n",
    "# GAS step\n",
    "\n",
    "dat_GAS_eda = dat_eda.groupby(['article_number', 'country']).apply(GAS_est).reset_index()\n",
    "dat_GAS_eda = pd.DataFrame(dat_GAS_eda.groupby(['article_number', 'year', 'week'])['GAS_est'].sum()).reset_index()\n",
    "\n",
    "# both = pd.read_excel('data/both.xlsx')\n",
    "# both['diff'] = both.apply(lambda row: row['net_forecast_y'] - row['net_forecast_x'], axis = 1)\n",
    "\n",
    "\n",
    "# SEASONALITY step\n",
    "\n",
    "seasonality_dat_eda = (dat_all[['article_number', 'year', 'week', 'country', 'season', 'net_qty', \n",
    "                                'sports_cat_desc', 'rmh_cat_desc', 'gender_desc', \n",
    "                                'age_group_desc', 'franchise', 'prod_grp_desc']].\n",
    "                       dropna().\n",
    "                       sort_values(['article_number', 'year', 'week']).\n",
    "                       copy()\n",
    "                  )\n",
    "\n",
    "# -- Sum over UK/EU, ADD article reference data --\n",
    "seasonality_dat_eda = pd.merge(\n",
    "    pd.DataFrame(seasonality_dat_eda.groupby(['article_number', 'season', 'year', 'week'])['net_qty'].sum()).reset_index(), # sum over UK & EU\n",
    "    seasonality_dat_eda[['article_number', 'sports_cat_desc', 'rmh_cat_desc', 'gender_desc', 'age_group_desc', 'franchise', 'prod_grp_desc']].drop_duplicates() # add reference information\n",
    "    ).dropna().sort_values(['article_number', 'year', 'week'])\n",
    "\n",
    "\n",
    "\n",
    "# -- Reliable, mirror seasons --\n",
    "seasonality_dat_eda = seasonality_dat_eda[seasonality_dat_eda.season.isin(['FW15', 'FW16', 'FW17', 'FW18', 'FW19'])]\n",
    "\n",
    "# ---- Calculate cat-level weekly means across *ALL SEASONS* ---- \n",
    "\n",
    "seasonality_sport   = pd.DataFrame(seasonality_dat_eda.groupby(['sports_cat_desc', 'week'])['net_qty'].mean()).reset_index().rename(columns = {'net_qty': 'sport_weekly_mean'})\n",
    "seasonality_rmh     = pd.DataFrame(seasonality_dat_eda.groupby(['rmh_cat_desc', 'week'])['net_qty'].mean()).reset_index().rename(columns = {'net_qty': 'rmh_weekly_mean'})\n",
    "seasonality_gndr    = pd.DataFrame(seasonality_dat_eda.groupby(['gender_desc', 'week'])['net_qty'].mean()).reset_index().rename(columns = {'net_qty': 'gender_weekly_mean'})\n",
    "seasonality_agegrp  = pd.DataFrame(seasonality_dat_eda.groupby(['age_group_desc', 'week'])['net_qty'].mean()).reset_index().rename(columns = {'net_qty': 'age_weekly_mean'})\n",
    "seasonality_frnchse = pd.DataFrame(seasonality_dat_eda.groupby(['franchise', 'week'])['net_qty'].mean()).reset_index().rename(columns = {'net_qty': 'franchise_weekly_mean'})\n",
    "seasonality_prdgrp  = pd.DataFrame(seasonality_dat_eda.groupby(['prod_grp_desc', 'week'])['net_qty'].mean()).reset_index().rename(columns = {'net_qty': 'prd_grp_weekly_mean'})\n",
    "\n",
    "seasonality_dfs = [seasonality_sport, seasonality_rmh, seasonality_gndr, seasonality_agegrp, seasonality_frnchse, seasonality_prdgrp]\n",
    "\n",
    "\n",
    "seasonality_dat_eda = seasonality_dat_eda[(seasonality_dat_eda.season == 'FW19') & (seasonality_dat_eda.article_number == aoi)]\n",
    "\n",
    "\n",
    "\n",
    "preds_eda = seasonality_dat_eda.groupby(['article_number']).apply(regress).reset_index()\n",
    "\n",
    "# Merge back with reference data\n",
    "preds_eda = pd.merge(\n",
    "    preds_eda,\n",
    "    seasonality_dat_eda,\n",
    "    how = 'left').sort_values(['article_number', 'week'])[['article_number', 'year', 'week', 'net_qty', 'seas_preds']] # .fillna(method='ffill')\n",
    "\n",
    "# Zero out negative preds\n",
    "preds_eda['seas_preds'] = np.where(preds_eda.seas_preds > 0, preds_eda.seas_preds, 0) \n",
    "\n",
    "# Combined observed weeks (partial season)  --- AND --- regression predicted (all) weeks\n",
    "preds_eda = pd.merge(\n",
    "    preds_eda,   # all weeks\n",
    "    dat_GAS_eda, # observed weeks\n",
    "    how = 'left')\n",
    "\n",
    "# weekly assignment of GAS, seasonality, or combination\n",
    "preds_eda['y_hat'] = np.where(np.isnan(preds_eda.GAS_est), preds_eda.seas_preds, (preds_eda.GAS_est + preds_eda.seas_preds)/2).round()\n",
    "\n",
    "# Sum over season\n",
    "# preds_season_eda = pd.DataFrame(preds_eda.groupby('article_number')['y_hat'].apply(sum).round())\n",
    "\n",
    "# Growth\n",
    "# preds_season_eda['y_hat'] = preds_season_eda.y_hat # * 1.1 # default growth rate\n",
    "                                           \n",
    "                                            \n",
    "                                            \n",
    "\n",
    "# EE7570_0 = preds_eda.copy()\n",
    "EE7570_0.head()\n",
    "\n",
    "# EE7570_1 = preds_eda.copy()\n",
    "\n",
    "EE7570_0.head()\n",
    "EE7570_1.head()\n",
    "\n",
    "both[both.article_number == aoi].head()\n",
    "\n",
    "both.shape\n",
    "# both[['net_forecast_x', 'net_forecast_y', 'diff']]\n",
    "\n",
    "both['diff'].describe().round()\n",
    "both['diff'].hist(bins = [-2500, 0, 1000, 12000])\n",
    "# without clearance ---- with clearance\n",
    "\n",
    "# both.to_excel('data/both.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# With/out clearance -- \n",
    "\n",
    "# With clearance --\n",
    "# dat_GAS0 = pd.DataFrame(dat_GAS.groupby('article_number')['GAS_est'].sum().round())\n",
    "# dat_GAS0.head()\n",
    "\n",
    "# Without clearance --\n",
    "# dat_GAS1 = pd.DataFrame(dat_GAS.groupby('article_number')['GAS_est'].sum().round())\n",
    "# dat_GAS1.head()\n",
    "\n",
    "# dat_GAS_both = pd.merge(\n",
    "#     dat_GAS0,\n",
    "#     dat_GAS1,\n",
    "#     left_index = True, right_index = True\n",
    "# )\n",
    "\n",
    "# dat_GAS_both['diff'] = dat_GAS0['GAS_est'] - dat_GAS1['GAS_est']\n",
    "\n",
    "# dat_GAS_both['diff'].hist()\n",
    "# dat_GAS_both['diff'].describe().round()\n",
    "\n",
    "\n",
    "# dat_GAS_both['lt0'] = (dat_GAS_both['diff'] <= 0)*1\n",
    "\n",
    "# dat_GAS_both['lt0'].mean().round(2)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

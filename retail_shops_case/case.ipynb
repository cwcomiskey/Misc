{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import bokeh.io\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "# init_notebook_mode()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import itertools\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "import time\n",
    "import dateutil.parser\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import gc\n",
    "import zipfile\n",
    "import sys, getopt\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from io import StringIO\n",
    "\n",
    "import dask.dataframe as dd\n",
    "#from chest import Chest\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "# Magic function to make matplotlib inline\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "import dask.dataframe as ddf\n",
    "import dask.array as da\n",
    "\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_rows', 800)\n",
    "\n",
    "import scipy\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.tsatools import detrend\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modules -- \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import bokeh.io\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "# init_notebook_mode()\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "\n",
    "# from collections import defaultdict\n",
    "# import csv\n",
    "# import itertools\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "import time\n",
    "import dateutil.parser\n",
    "# import pickle\n",
    "import random\n",
    "\n",
    "# import gc\n",
    "# import zipfile\n",
    "# import sys, getopt\n",
    "# import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from io import StringIO\n",
    "\n",
    "# import dask.dataframe as dd\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "# Magic function to make matplotlib inline\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "# import dask.dataframe as ddf\n",
    "# import dask.array as da\n",
    "\n",
    "# pd.set_option('max_columns', 500)\n",
    "# pd.set_option('max_rows', 800)\n",
    "\n",
    "import scipy\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# from statsmodels.tsa.tsatools import detrend\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KPN Group sells its products through different channels. \n",
    "* online \n",
    "* telephone \n",
    "* retail stores\n",
    "* third-party stores. \n",
    "\n",
    "The KPN formula in the streets:\n",
    "* KPN shop -- only **KPN**\n",
    "* TELFORT shop (KPN subsidiary) -- only **Telfort**\n",
    "* MULTIBRAND store -- combines the brands **KPN, Telfort and XS4ALL**,\n",
    "* KPN XL store -- combines the consumer and small business segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research questions\n",
    "\n",
    "1. Which **characteristics** are most important for predicting the (contracted) revenue per store formula (Telfort, KPN, KPN XL)?\n",
    "\n",
    "Stuff I've already done\n",
    "\n",
    "2. Which **TELFORT** stores should be transformed into **KPN** stores, and what is the expected (contracted) revenue after this transformation?\n",
    "\n",
    "(i) Highest sellers, or \n",
    "\n",
    "(ii) highest sellers using KPN regression model predictions\n",
    "\n",
    "3. Our budget enables the transformation of 5 **KPN** stores into **KPN XL** stores. Which KPN stores should we transform to optimize the revenue?\n",
    "\n",
    "Same as (2)\n",
    "\n",
    "4. Possibly continue with remaining questions to complete this advice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "* We find it more important that you are able to **communicate and defend** your advice well, than that you build the most advanced model. \n",
    "* think about the complexity of the solution you choose in order to explain your decisions to an audience without explicit data science background. \n",
    "* We do value a solid reasoning behind the chosen data transformations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please send the **two files before noon the day prior** to the walkthrough and presentation sessions to Tom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case = pd.read_csv('dataset_shops.csv',\n",
    "                   usecols = ['date', 'shop_id', 'committed_revenues_main_inc_vat', 'place', \n",
    "                              'shop_formula', 'dist_shop_closest_km', 'no_retail_shops', \n",
    "                              'no_companies', 'perc_owned_vs_rented_houses', \n",
    "                              'avg_value_household', 'avg_household_size', 'no_residents'])\n",
    "\n",
    "# Other columns: tons of NA, not particularly relevant to question of interest (at first pass anyway)\n",
    "\n",
    "case.date = pd.to_datetime(case.date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Levels of categoricals -- \n",
    "\n",
    "# for c in case.columns:\n",
    "#     if type(case[c][0]) != np.float64:\n",
    "#         print(c, len(case[c].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NA EDA --- \n",
    "\n",
    "for c in [case.columns]:\n",
    "    print(case[c].isna().sum())\n",
    "\n",
    "c_subset = case[pd.isnull(case).any(axis=1)].copy()\n",
    "\n",
    "for c in ['shop_id', 'place', 'shop_formula']:\n",
    "    print(c, c_subset[c].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No time-varying covariates, so weekly observation completely unnecessary/incorrect (wildly violates linear regression assumptions) \n",
    "* Donâ€™t want to penalize stores for shorter timelines or missing weeks, so weekly avg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aggregate\n",
    "\n",
    "case = pd.merge(\n",
    "    pd.DataFrame(case.groupby(['shop_id'])['committed_revenues_main_inc_vat'].mean().round().reset_index()),\n",
    "    case[['shop_formula', 'shop_id', 'place', 'dist_shop_closest_km', 'no_retail_shops',\n",
    "       'no_companies', 'perc_owned_vs_rented_houses', 'avg_value_household',\n",
    "       'avg_household_size', 'no_residents']].drop_duplicates()\n",
    ").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case2 = pd.get_dummies(case[['committed_revenues_main_inc_vat', 'shop_formula',\n",
    "       'dist_shop_closest_km', 'no_retail_shops', 'no_companies',\n",
    "       'perc_owned_vs_rented_houses', 'avg_value_household',\n",
    "       'avg_household_size', 'no_residents']]).rename(\n",
    "    columns = { \n",
    "        'committed_revenues_main_inc_vat': 'committed_rev',\n",
    "        'avg_value_household': 'avg_house_value',\n",
    "        'perc_owned_vs_rented_houses': 'pct_own_v_rent',\n",
    "        'shop_formula_KPN XL winkel': 'KPN_XL',\n",
    "        'shop_formula_KPN winkel': 'KPN', \n",
    "        'shop_formula_Telfort': 'Telfort'\n",
    "    }\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case2[['KPN_XL', 'KPN', 'Telfort']].sum()\n",
    "\n",
    "# Unlikely to draw any solid conclusions from KPN_XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add formula-feature interactions (importance by shop type)\n",
    "\n",
    "for form in ['KPN_XL', 'KPN', 'Telfort']:\n",
    "    for feat in ['dist_shop_closest_km', 'no_retail_shops', 'no_companies', 'pct_own_v_rent', 'avg_house_value', 'avg_household_size', 'no_residents']:\n",
    "        case2[str(form + '_' + feat)] = case2[form]*case2[feat]\n",
    "        \n",
    "# Drop original covariates\n",
    "case2 = case2.drop(['dist_shop_closest_km', 'no_retail_shops', 'no_companies', 'pct_own_v_rent', \n",
    "                    'avg_house_value', 'avg_household_size', 'no_residents'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Response, covariates (turn into markdown) -- \n",
    "\n",
    "case2.columns\n",
    "\n",
    "# ['committed_rev', \n",
    "  \n",
    "#     'KPN_XL_dist_shop_closest_km', 'KPN_XL_no_retail_shops', 'KPN_XL_no_companies', 'KPN_XL_pct_own_v_rent',\n",
    "#     'KPN_XL_avg_house_value', 'KPN_XL_avg_household_size', 'KPN_XL_no_residents', \n",
    " \n",
    "#     'KPN_dist_shop_closest_km', 'KPN_no_retail_shops', 'KPN_no_companies', 'KPN_pct_own_v_rent',\n",
    "#     'KPN_avg_house_value', 'KPN_avg_household_size', 'KPN_no_residents',\n",
    " \n",
    "#     'Telfort_dist_shop_closest_km', 'Telfort_no_retail_shops', 'Telfort_no_companies', 'Telfort_pct_own_v_rent',\n",
    "#     'Telfort_avg_house_value', 'Telfort_avg_household_size', 'Telfort_no_residents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = case2['committed_rev']\n",
    "X = case2.drop('committed_rev', axis = 1) \n",
    "\n",
    "mod = sm.OLS(y, X, missing='drop').fit()\n",
    "mod.rsquared.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Also calculate R^2 Manually (Sanity check) -- \n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_true = y\n",
    "y_pred = mod.predict(X)\n",
    "\n",
    "y_bar = y_true.mean()\n",
    "\n",
    "SSReg = ((y_pred - y_bar)**2).sum()\n",
    "SSRes = ((y_pred - y_true)**2).sum()\n",
    "SSTot = ((y_true - y_bar)**2).sum()\n",
    "\n",
    "# Model\n",
    "mod.rsquared.round(2)\n",
    "\n",
    "# Manually\n",
    "(1 - SSRes/SSTot).round(2)\n",
    "\n",
    "# sklearn \n",
    "(r2_score(y_true, y_pred)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod.summary().tables[0]\n",
    "\n",
    "# Statistically significant model*: huge F-stat \n",
    "# Quite high R^2\n",
    "\n",
    "# *assuming regression requirements met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mod.summary().tables[1]\n",
    "p = pd.DataFrame(data = mod.pvalues.round(3), columns = ['p_values'])\n",
    "p.sort_values(['p_values'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop three weakest covariates for each formula\n",
    "case2 = case2.drop(['KPN_no_retail_shops', 'KPN_avg_house_value', 'KPN_pct_own_v_rent',                 # KPN\n",
    "                    'KPN_XL_no_residents', 'KPN_XL_pct_own_v_rent', 'KPN_XL_dist_shop_closest_km',      # XL\n",
    "                    'Telfort_avg_house_value', 'Telfort_no_companies', 'Telfort_dist_shop_closest_km'], # TELFORT \n",
    "                   axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = case2['committed_rev']\n",
    "X = case2.drop('committed_rev', axis = 1) \n",
    "\n",
    "mod = sm.OLS(y, X, missing='drop').fit()\n",
    "mod.rsquared.round(2)\n",
    "mod.summary().tables[0]\n",
    "\n",
    "# R^2 virtually unchanged, model still extremely significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod.summary().tables[1]\n",
    "p = pd.DataFrame(data = mod.pvalues.round(3), columns = ['p_values'])\n",
    "p.reset_index().sort_values(['index'], ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.pvalues.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop addt'l weak covariates, refit\n",
    "case2 = case2.drop(['KPN_avg_household_size',                    \n",
    "                    'KPN_XL_avg_household_size',\n",
    "                    'Telfort_avg_household_size',\n",
    "                    'Telfort_pct_own_v_rent'\n",
    "                   ], axis = 1)\n",
    "\n",
    "y = case2['committed_rev']\n",
    "X = case2.drop('committed_rev', axis = 1) \n",
    "\n",
    "mod = sm.OLS(y, X, missing='drop').fit()\n",
    "mod.rsquared.round(2)\n",
    "mod.summary().tables[0]\n",
    "mod.summary().tables[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concerns:\n",
    "# Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EDA: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kpn = case[case.shop_formula == 'KPN winkel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shops per place --> only 7 places with > 1 shops\n",
    "\n",
    "(kpn[['place', 'shop_id']].\n",
    " drop_duplicates().\n",
    " groupby('place')['shop_id'].\n",
    " count().\n",
    " sort_values(ascending = False)\n",
    ")[:15]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aggregate to monthly, plot a few for EDA\n",
    "\n",
    "kpn_monthly = (kpn[['date', 'shop_id', 'committed_revenues_main_inc_vat', 'place']].\n",
    "              set_index('date').\n",
    "              groupby(['place', 'shop_id']).\n",
    "              resample('W').sum().reset_index().copy())\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = [20, 5]\n",
    "# places = np.random.choice(kpn.shop_id.unique(), size = 5, replace = False)\n",
    "\n",
    "# kpn_monthly_mini = kpn_monthly[kpn_monthly.shop_id.isin([places])]\n",
    "# kpn_monthly_mini = kpn_monthly[kpn_monthly.place == 'amsterdam']\n",
    "\n",
    "# kpn_plot = kpn_monthly_mini.pivot(index = 'date', columns = 'shop_id', values='committed_revenues_main_inc_vat')\n",
    "# kpn_plot.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kpn2 = pd.merge(\n",
    "    pd.DataFrame(kpn.groupby(['shop_id'])['committed_revenues_main_inc_vat'].mean().round().reset_index()),\n",
    "    kpn[['shop_id', 'place', 'dist_shop_closest_km', 'no_retail_shops',\n",
    "       'no_companies', 'perc_owned_vs_rented_houses', 'avg_value_household',\n",
    "       'avg_household_size', 'no_residents']].drop_duplicates()\n",
    ").dropna()\n",
    "\n",
    "# kpn2[pd.isnull(kpn2).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make indicator w/ interaction, or quadratic\n",
    "\n",
    "plt.scatter(x = kpn2.no_residents, y = kpn2.committed_revenues_main_inc_vat)\n",
    "\n",
    "# (1) NOTHING: perc_owned_vs_rented_houses, avg_household_size, avg_value_household\n",
    "# (2) PATTERN: no_residents, no_retail_shops, no_companies\n",
    "# (3) UNCLEAR: 'dist_shop_closest_km',\n",
    "\n",
    "# Make indicator w/ interaction, or quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature: no_residents -- \n",
    "\n",
    "# Quadratic\n",
    "# kpn2.loc[:,'no_residents2'] = kpn2.no_residents**2\n",
    "# X = kpn2[['no_residents', 'no_residents2']] \n",
    "# X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "# Indicators\n",
    "kpn2.loc[:,'no_residents_lt'] = np.where(kpn2.no_residents < 400000, kpn2.no_residents, 0)\n",
    "kpn2.loc[:,'no_residents_gt'] = np.where(kpn2.no_residents > 400000, kpn2.no_residents, 0)\n",
    "kpn2.loc[:, 'c_lt'] = (kpn2['no_residents_lt'] != 0)*1\n",
    "kpn2.loc[:, 'c_gt'] = (kpn2['no_residents_gt'] != 0)*1\n",
    "X = kpn2[['c_lt', 'no_residents_lt', 'c_gt', 'no_residents_gt']]\n",
    "\n",
    "y = kpn2['committed_revenues_main_inc_vat']\n",
    "\n",
    "# Regression\n",
    "mod = sm.OLS(y, X, missing='drop').fit()\n",
    "mod.rsquared.round(2)\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 5]\n",
    "\n",
    "# Quadratic Regression plot\n",
    "# x1 = np.arange(1, 900000, 50000)\n",
    "# x = pd.DataFrame(data = {'int': 1, 'no_res': x1, 'no_res2': x1**2})\n",
    "# plt.plot(x1, mod.predict(x))\n",
    "\n",
    "\n",
    "# Indicator Regression Plot\n",
    "x_lt = np.arange(1, 400000, 50000)\n",
    "plt.plot(x_lt, mod.predict(pd.DataFrame(data = {'c_lt': 1, 'no_res_lt': x_lt, 'c_gt': 0, 'no_res_gt': 0})))\n",
    "x_gt = np.arange(400000, 900000, 50000)\n",
    "plt.plot(x_gt, mod.predict(pd.DataFrame(data = {'c_lt': 0, 'no_res_lt': 0,    'c_gt': 1, 'no_res_gt': x_gt})))\n",
    "\n",
    "\n",
    "# Empirical Plot\n",
    "plt.scatter(kpn2.no_residents, kpn2.committed_revenues_main_inc_vat)\n",
    "\n",
    "\n",
    "\n",
    "# Indicator R^2: 0.26\n",
    "# Quadratic R^2: 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# no_retail_shops -- \n",
    "\n",
    "# kpn2.loc[:,'no_retail_shops2'] = kpn2.no_retail_shops**2\n",
    "\n",
    "kpn2.loc[:,'no_retail_shops_lt'] = np.where(kpn2.no_retail_shops < 7500, kpn2.no_retail_shops, 0)\n",
    "kpn2.loc[:,'no_retail_shops_gt'] = np.where(kpn2.no_retail_shops > 7500, kpn2.no_retail_shops, 0)\n",
    "\n",
    "y = kpn2['committed_revenues_main_inc_vat']\n",
    "X = kpn2[['no_retail_shops_lt', 'no_retail_shops_gt']] \n",
    "X = sm.add_constant(X)\n",
    "\n",
    "mod = sm.OLS(y, X, missing='drop').fit()\n",
    "mod.rsquared.round(2)\n",
    "mod.summary()\n",
    "\n",
    "x1 = np.arange(1, 22000, 1000)\n",
    "\n",
    "# x = pd.DataFrame(data = {'int': 1, 'no_res': x1, 'no_res2': x1**2})\n",
    "\n",
    "x = pd.DataFrame(data = {'int': 1, 'no_ret_shops_lt': (x1 < 7500)*x1, 'no_ret_shops_gt': (x1 > 7500)*x1})\n",
    "\n",
    "# Indicator Regression Plot\n",
    "x_lt = np.arange(1, 7500, 500)\n",
    "plt.plot(x_lt, mod.predict(pd.DataFrame(data = {'int': 1, 'no_ret_shops_lt': x_lt, 'no_ret_shops_gt': 0})))\n",
    "\n",
    "x_gt = np.arange(7500, 22000, 500)\n",
    "plt.plot(x_gt, mod.predict(pd.DataFrame(data = {'int': 1, 'no_ret_shops_lt': 0, 'no_ret_shops_gt': x_gt})))\n",
    "\n",
    "# Quadratic\n",
    "# plt.plot(x1, mod.predict(x))\n",
    "\n",
    "# Empirical\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 5]\n",
    "plt.scatter(kpn2.no_retail_shops, kpn2.committed_revenues_main_inc_vat)\n",
    "\n",
    "# Conclusion: weak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# no_companies -- \n",
    "kpn2.loc[:,'no_companies2'] = kpn2.no_companies**2\n",
    "\n",
    "y = kpn2['committed_revenues_main_inc_vat']\n",
    "X = kpn2[['no_companies', 'no_companies2']] \n",
    "X = sm.add_constant(X)\n",
    "\n",
    "mod = sm.OLS(y, X, missing='drop').fit()\n",
    "mod.rsquared.round(2)\n",
    "mod.summary()\n",
    "\n",
    "x1 = np.arange(1, kpn2.no_companies.max(), 1000)\n",
    "x = pd.DataFrame(data = {'int': 1, 'no_res': x1, 'no_res2': x1**2})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 5]\n",
    "plt.plot(x1, mod.predict(x))\n",
    "plt.scatter(kpn2.no_companies, kpn2.committed_revenues_main_inc_vat)\n",
    "\n",
    "# Weak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Telfort -- \n",
    "\n",
    "telfort = case[case.shop_formula == 'Telfort']\n",
    "\n",
    "telfort2 = pd.merge(\n",
    "    pd.DataFrame(telfort.groupby(['shop_id'])['committed_revenues_main_inc_vat'].mean().round().reset_index()),\n",
    "    telfort[['shop_id', 'place', 'dist_shop_closest_km', 'no_retail_shops',\n",
    "       'no_companies', 'perc_owned_vs_rented_houses', 'avg_value_household',\n",
    "       'avg_household_size', 'no_residents']].drop_duplicates()\n",
    ").dropna()\n",
    "\n",
    "\n",
    "plt.scatter(x = telfort2.no_residents, y = telfort2.committed_revenues_main_inc_vat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# R squared shenanigans\n",
    "\n",
    "y_true = pd.Series([3, -0.5, 2])\n",
    "y_pred = pd.Series([2.5, 0.0, 2])\n",
    "\n",
    "y_bar = y_true.mean()\n",
    "\n",
    "SSReg = ((y_pred - y_bar)**2).sum()\n",
    "SSRes = ((y_pred - y_true)**2).sum()\n",
    "SSTot = ((y_true - y_bar)**2).sum()\n",
    "\n",
    "SSReg/SSTot\n",
    "\n",
    "# --- WHY ARE THESE DIFFERENT?? ---\n",
    "\n",
    "1 - SSRes/SSTot\n",
    "\n",
    "r2_score(y_true, y_pred)  \n",
    "\n",
    "# -----------------------------------------\n",
    "\n",
    "# SSTot = ((y - y.mean())**2).sum()\n",
    "# SSRes = ((y - mod.predict(X))**2).sum()\n",
    "# SSReg = ((mod.predict(X) - y.mean())**2).sum()\n",
    "\n",
    "# (1 - SSRes/SSTot).round(3)\n",
    "# (SSReg/SSTot).round(3)\n",
    "\n",
    "# r2_score(y, mod.predict(X)).round(2)\n",
    "\n",
    "#mod.summary()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

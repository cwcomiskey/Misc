{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import clone\n",
    "from sklearn.externals.six.moves import xrange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import bokeh.io\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "# init_notebook_mode()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import itertools\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "import time\n",
    "import dateutil.parser\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import gc\n",
    "import zipfile\n",
    "import sys, getopt\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from io import StringIO\n",
    "\n",
    "import dask.dataframe as dd\n",
    "#from chest import Chest\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "# Magic function to make matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "import dask.dataframe as ddf\n",
    "import dask.array as da\n",
    "\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Overstock-SupplyChain-Understock (OSU) Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# dat0 = pd.read_csv('Transaction data.csv', low_memory=False) # *** DATA ***\n",
    "# dat0['consumer_order_date'] = pd.to_datetime(dat0['consumer_order_date'])\n",
    "\n",
    "# dat = dat0.copy()\n",
    "# dat = dat[['consumer_order_date', 'article_number', 'gross_demand_quantity', 'Clearance', 'season']]\n",
    "\n",
    "# # Subset to non-clearance transactions only --- change here for David/Mike's request\n",
    "# dat = dat[dat['Clearance'] == 0]\n",
    "\n",
    "# #dat = dat[dat['article_number'] == 'M20325']\n",
    "\n",
    "# # 'aggregate' to weekly sums by article for buy_availability merge and adjustment\n",
    "# dat.set_index('consumer_order_date', inplace = True)\n",
    "\n",
    "# dat = dat[['article_number', 'season', 'gross_demand_quantity']].groupby(['article_number', 'season']).resample('W').sum()\n",
    "# dat.reset_index(inplace=True)\n",
    "\n",
    "# # Add 'week' and 'year' for merging with stock (buy_availability) data (b/c min_date_of_week)\n",
    "# dat['week'] = [t.week for t in dat['consumer_order_date']]\n",
    "# dat['year'] = [t.year for t in dat['consumer_order_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat.to_csv('dat_all_transactions_weekly.csv')\n",
    "\n",
    "dat = pd.read_csv('dat_all_transactions_weekly.csv', low_memory=False, index_col = 0)\n",
    "dat['consumer_order_date'] = pd.to_datetime(dat['consumer_order_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock data\n",
    "dat_stock16 = pd.read_csv('Stock Data/Stock data 2016.csv', low_memory=False, index_col = 0) # *** DATA ***\n",
    "dat_stock17 = pd.read_csv('Stock Data/Stock data 2017.csv', low_memory=False, index_col = 0) # *** DATA ***\n",
    "dat_stock18 = pd.read_csv('Stock Data/Stock data 2018.csv', low_memory=False, index_col = 0) # *** DATA ***\n",
    "dat_stock19 = pd.read_csv('Stock Data/Stock data 2019.csv', low_memory=False, index_col = 0) # *** DATA ***\n",
    "\n",
    "dat_stock = pd.concat([dat_stock16, dat_stock17, dat_stock18, dat_stock19])\n",
    "del dat_stock16, dat_stock17, dat_stock18, dat_stock19\n",
    "dat_stock['min_date_of_week'] = pd.to_datetime(dat_stock['min_date_of_week'])\n",
    "\n",
    "# dat_stock = dat_stock[dat_stock['article_number'] == 'M20325']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tidy\n",
    "dat_stock.reset_index(inplace = True)\n",
    "dat_stock.drop(['avg(ecom_available_stock)', 'avg(size_availability)'], axis = 1, inplace = True)\n",
    "dat_stock.rename(columns = {'min_date_of_week': 'date', 'avg(buy_availability)': 'buy_availability'}, inplace = True)\n",
    "\n",
    "# Filter to SS20_range carryovers\n",
    "# dat_stock = dat_stock[[(a in SS20_range) for a in dat_stock['article_number']]]\n",
    "\n",
    "dat_stock['date'] = pd.to_datetime(dat_stock['date'])\n",
    "\n",
    "# For merging with transaction data\n",
    "dat_stock['week'] = [t.week for t in dat_stock['date']]\n",
    "dat_stock['year'] = [t.year for t in dat_stock['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = dat_stock['date'].min()\n",
    "dat = dat[dat['consumer_order_date'] > min_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge weekly demand df and buy_availability df -- for understock correction\n",
    "dat = pd.merge(dat, dat_stock, \n",
    "               left_on = ['article_number', 'year', 'week'], \n",
    "               right_on = ['article_number', 'year', 'week'],\n",
    "               how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv('NaNs_for_Joerian.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['buy_availability'] = dat['buy_availability'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----- Calculate *observed* full season gross_demand_quantity per article -----\n",
    "\n",
    "dat_season = pd.DataFrame(dat.groupby(['article_number', 'season'])['gross_demand_quantity'].sum())\n",
    "dat_season.rename(columns = {'gross_demand_quantity':'season_gross_demand_quantity'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# WEEKLY averages for articles when buy_availability > 0.35\n",
    "dat_stocked = pd.DataFrame(\n",
    "    dat[dat['buy_availability'] > 0.35].\n",
    "    groupby(['article_number', 'season'])['gross_demand_quantity'].\n",
    "    mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "dat_stocked.rename(columns = {'gross_demand_quantity':'corrected_weekly_avg_gross_demand_quantity'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extend to full season (26 weeks) to estimate full season demand\n",
    "dat_stocked['corrected_gross_demand_quantity'] = 26*dat_stocked['corrected_weekly_avg_gross_demand_quantity'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat_season = pd.merge(dat_season, dat_stocked, left_index=True, right_index=True, how = 'outer')\n",
    "dat_season.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_season = dat_season[(dat_season['season'] != 'FW16') & \n",
    "                        (dat_season['season'] != 'SS16') &\n",
    "                        (dat_season['season_gross_demand_quantity'] > 50)\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT JOERIAN ON THIS\n",
    "\n",
    "dat_season[dat_season['corrected_gross_demand_quantity'].isna()] \n",
    "dat[dat['article_number'] == 'AC7085'] # e.g.\n",
    "\n",
    "# How many NaN\n",
    "dat[dat['buy_availability'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.merge(dat, dat_season[['article_number', 'season', 'corrected_weekly_avg_gross_demand_quantity']])\n",
    "\n",
    "dat['OSU_gross_demand_quantity'] = np.where(dat['buy_availability'] < 0.35,\n",
    "                                            dat['corrected_weekly_avg_gross_demand_quantity'],\n",
    "                                            dat['gross_demand_quantity']\n",
    "                                           )\n",
    "\n",
    "dat = dat[['article_number', 'season', 'consumer_order_date', \n",
    "           'gross_demand_quantity', 'buy_availability', 'OSU_gross_demand_quantity']].round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dat.article_number.unique())\n",
    "dat.season.value_counts()\n",
    "len(dat.consumer_order_date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv('weekly_OSU_transaction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = dat[dat['article_number'] == 'M20325']\n",
    "# dat_stocked = dat_stocked[dat_stocked['article_number'] == 'M20325']"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

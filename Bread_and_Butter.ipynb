{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Load Modules, submodules, classes, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import scipy\n",
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import clone\n",
    "from sklearn.externals.six.moves import xrange\n",
    "from scipy import spatial\n",
    "from scipy.spatial import cKDTree\n",
    "#from pyramid.arima import auto_arima\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import bokeh.io\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "# from bokeh import charts\n",
    "\n",
    "# init_notebook_mode()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import itertools\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "import time\n",
    "import dateutil.parser\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "import gc\n",
    "import zipfile\n",
    "import sys, getopt\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from io import StringIO\n",
    "\n",
    "import dask.dataframe as dd\n",
    "#from chest import Chest\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables SVG graphics inline.  There is a bug, so uncomment if it works.\n",
    "# %config InlineBackend.figure_formats = {'svg',}\n",
    "\n",
    "# This enables high resolution PNGs. SVG is preferred, but has problems\n",
    "# rendering vertical and horizontal lines\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "import dask.dataframe as ddf\n",
    "import dask.array as da\n",
    "#from dask import distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dat0 = pd.read_csv('seasonal_sales_indicators.csv',\n",
    "                 delimiter = '~')\n",
    "\n",
    "# len(dat0['article_number'].unique()) # 46573"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat.columns = [x.replace('t_eu_ecom_dit_dsf_transaction_t.', '') for x in dat.columns] # tidy column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = dat[dat['gross_demand_quantity'] != 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = dat[['article_number', 'gross_demand_quantity', 'sold_qty',\n",
    "       'net_qty', 'gross_sales_gross_disc_net_ret',\n",
    "       'gross_sales_net_disc_gross_ret', 'net_sales', 'total_markdown',\n",
    "       'temporary_markdown', 'permanent_markdown', 'employee_markdown',\n",
    "       'fraction_of_full_price', 'markdown', 'sale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat['sales_price'] = dat['net_sales'].divide(dat['gross_demand_quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dat_grouped = dat.groupby(by = 'article_number')\n",
    "\n",
    "functions = ['min', 'median', 'mean', 'max', 'std', 'sum', 'count']\n",
    "dat = dat_grouped.agg(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat['Count'] = dat['sold_qty']['count']\n",
    "dat.drop('count', level = 1, axis = 1, inplace = True) # # Drop redundant 'count' columns\n",
    "\n",
    "dat.fillna(value=0, inplace = True) # Define single transaction article std to be 0\n",
    "dat = dat.replace([np.inf, -np.inf, np.nan], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Save/Load curated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save/load tidied version\n",
    "\n",
    "# dat.to_csv('dat.csv')\n",
    "\n",
    "dat = pd.read_csv('dat.csv', low_memory=False, index_col = 0, header = [0,1]) # gotta encode multi-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Principal Component Analysis (for 2-D visualizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# SCALING: zero mean and unit variance \n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(dat)\n",
    "# dat_scaled = scaler.transform(dat)\n",
    "\n",
    "# PRINCIPAL COMPONENT ANALYSIS\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2) # keep the first two principal components of the data\n",
    "pca.fit(dat)\n",
    "\n",
    "# transform data onto the first two principal components\n",
    "dat_pca = pca.transform(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EDA \n",
    "np.isnan(np.log(dat_pca[:,0])).sum()\n",
    "(dat_pca[:,1] < 0).sum()\n",
    "(pd.DataFrame(dat_pca)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# K-means clustering  --------------------  --------------------\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 10)\n",
    "kmeans.fit(dat)\n",
    "\n",
    "Kmeans = pd.Series(kmeans.predict(dat)) # Cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reclassify: majority/non as 0/1 \n",
    "\n",
    "Kmeans.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Kmeans = (Kmeans != 0)*1 # lone vector\n",
    "Kmeans.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat['Kmeans'] = Kmeans.values\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update(mpl.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(dat_pca[:,0], \n",
    "#             dat_pca[:,1], \n",
    "#             c = Kmeans,\n",
    "#             alpha = 0.05)\n",
    "\n",
    "# plt.xlabel('PC1')\n",
    "# plt.ylabel('PC2')\n",
    "\n",
    "# plt.xscale('symlog')\n",
    "# plt.yscale('symlog')\n",
    "\n",
    "plt.scatter(dat['sales_price']['mean'], \n",
    "            np.log(dat['sold_qty']['sum']), \n",
    "            c = Kmeans,\n",
    "            alpha = 0.05)\n",
    "\n",
    "plt.xlabel('Sales Price')\n",
    "plt.ylabel('log(sold_qty)')\n",
    "\n",
    "plt.colorbar()\n",
    "plt.rcParams[\"figure.figsize\"] = [12,12]\n",
    "plt.title('K-means Classification')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram: total gross demand quantity, basic items\n",
    "dat[(dat['Kmeans'] == 0) & (dat['gross_demand_quantity']['sum'] < 1000)]['gross_demand_quantity']['sum'].hist(bins = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram: total gross_demand_quantity, non-basic items\n",
    "dat[(dat['Kmeans'] != 0) & (dat['gross_demand_quantity']['sum'] < 10000)]['gross_demand_quantity']['sum'].hist(bins = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram: sales_price, basic items\n",
    "dat[dat['Kmeans'] == 0]['sales_price']['mean'].hist(bins = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram: sales_price, non-basic items\n",
    "dat[(dat['Kmeans'] != 0) & (dat['sales_price']['mean'] != 0)]['sales_price']['mean'].hist(bins = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Agglomerative Clustering -------------\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agg = AgglomerativeClustering(n_clusters = 10)\n",
    "agglom = pd.Series(agg.fit_predict(dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Reclassify: majority/non as 0/1 \n",
    "\n",
    "agglom.value_counts()\n",
    "agglom = (agglom != 1)*1 # lone vector\n",
    "agglom.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.log(dat['net_sales']['sum']), \n",
    "            np.log(dat['sold_qty']['sum']), \n",
    "            c = agglom,\n",
    "            alpha = 0.15)\n",
    "plt.xlabel('log(net_sales)')\n",
    "plt.ylabel('log(sold_qty)')\n",
    "plt.colorbar()\n",
    "plt.title('Agglomerative Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 DBSCAN - 'density based spatial clustering of applications with noise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dat)\n",
    "dat_scaled = scaler.transform(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN()\n",
    "dbs = pd.Series(dbscan.fit_predict(dat_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Reclassify: majority/non as 0/1 \n",
    "dbs01 = (dbs != -1)*1 # lone vector\n",
    "dbs01.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.log(dat['net_sales']['sum']), \n",
    "            np.log(dat['sold_qty']['sum']), \n",
    "            c = dbs01,\n",
    "            alpha = 0.15)\n",
    "plt.xlabel('log(net_sales)')\n",
    "plt.ylabel('log(sold_qty)')\n",
    "plt.colorbar()\n",
    "plt.title('DBSCAN Classification')\n",
    "plt.rcParams[\"figure.figsize\"] = [16,16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Cross-method comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### 2.4.1 K-means x Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame(data = {'Ag': agglom, 'Km': Kmeans})\n",
    "table.groupby(['Ag', 'Km']).size()\n",
    "# 3924/46573 # disagreement\n",
    "\n",
    "# table[(table['Ag'] == 0) & (table['Km'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Meta-Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Import, Process Article Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Key 1 = article number <----> group article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 'article_descr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = pd.read_csv('dat.csv', low_memory=False, index_col = 0, header = [0,1]) # gotta encode multi-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat2 = pd.read_csv('article_reference_data_y2016_18.csv',\n",
    "                 delimiter = '~',\n",
    "                  low_memory = False,\n",
    "                   usecols=['group_article', 'brand', 'sub_brand', 'season_create', 'season_active',\n",
    "                            'graphic', 'gender', 'age_group', 'retail_intro_date_global',\n",
    "                            'retail_exit_date_global', 'material_technology', 'pictogram_composition',\n",
    "                            'price_band', 'gender_age', 'construction_type', 'length_mes_uom_dim',\n",
    "                            'uom_dim', 'height_mes_uom_dim', 'width_mes_uom_dim', 'article_descr',\n",
    "                            'drop_season', 'uom_vol', 'uom_wgt', 'product_fit', 'material_way_type',\n",
    "                            'outer_sole_main_material', 'inner_sole_main_material', 'main_material_lining',\n",
    "                            'main_material_upper', 'dimension_uov', 'dimension_uom', 'carried_over_from',\n",
    "                            'drop_date', 'retail_exit_tgt_season', 'product_franchise', 'age_group_descr',\n",
    "                            'brand_descr', 'sub_brand_descr', 'lifecylce_status_prod_descr', 'brand_asset_descr',\n",
    "                            'rmh_retail_class_descr', 'rmh_retail_department_descr', 'rmh_retail_sub_class_descr',\n",
    "                            'rmh_retail_sub_dept_descr', 'rmh_category_descr', 'rmh_gender_descr',\n",
    "                            'rmh_retail_section_descr', 'rmh_product_division_descr', 'rmh_product_type_descr',\n",
    "                            'spm_color_first_descr', 'spm_color_second_descr', 'spm_color_third_descr',\n",
    "                            'spm_color_fourth_descr', 'product_franchise_descr'\n",
    "                           ]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = dat2[['group_article', 'article_descr']]\n",
    "dat2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat[['Kmeans']]\n",
    "dat['article'] = dat.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.merge(dat, dat2, left_on= 'article', right_on= 'group_article')\n",
    "dat3.columns = ('Kmeans', 'article', 'article2', 'descr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3[dat3['Kmeans'] == 0]['descr'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
